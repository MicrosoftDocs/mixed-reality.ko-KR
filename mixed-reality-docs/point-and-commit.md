---
title: 지점 및 실습을 사용 하 여 커밋
description: 지점 및 커밋 입력된 모델 개요
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 지금까지 가리키고 커밋 혼합 현실을, 상호 작용, 디자인, hololens, 실습,
ms.openlocfilehash: 30f85d2bb455abab3a533e0a829b4fba8cea0a7a
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402379"
---
# <a name="point-and-commit-with-hands"></a><span data-ttu-id="bf8f0-104">지점 및 실습을 사용 하 여 커밋</span><span class="sxs-lookup"><span data-stu-id="bf8f0-104">Point and commit with hands</span></span>
<span data-ttu-id="bf8f0-105">지점 및 실습을 사용 하 여 커밋은 사용자가 대상으로 선택 하 고 거리의 2D 콘텐츠 및 3D 개체를 조작할 수 있는 입력된 모델.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-105">Point and commit with hands is an input model that enables users to target, select and manipulate 2D content and 3D objects in the distance.</span></span> <span data-ttu-id="bf8f0-106">이 "훨씬" 상호 작용 방법이 혼합된 현실에 고유한 및 방식으로 사용자를 자연스럽 게은 실제 세계와 intereact 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-106">This "far" interaction technique is unique to mixed reality and is not a way humans naturally intereact with the real world.</span></span> <span data-ttu-id="bf8f0-107">슈퍼 hero 동영상에 예를 들어 *X Men*, 문자 [마그네틱](https://en.wikipedia.org/wiki/Magneto_(comics)) 연락 박수를 사용 하 여 거리가 먼 개체를 조작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-107">For example, in the super hero movie *X-Men*, the character [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) is capable of reaching out and manipulating a far object in the distance with his hands.</span></span> <span data-ttu-id="bf8f0-108">이 사람이 실제로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-108">This is not something humans can do in reality.</span></span> <span data-ttu-id="bf8f0-109">HoloLens (AR) 및 혼합 현실 VR ()에서 주요 holographic 콘텐츠로 매력적인 환경을 뿐만 아니라 더 효과적이 고 효율적인 상호 작용 하도록 실제 세계의 물리적 제한을이 마법의 power 사용 하 여 사용자를 장착할 했습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-109">In both HoloLens (AR) and Mixed Reality (VR), we equip users with this magical power, breaking the physical constraint of the real world not only to have a delightful experience with holographic contents but also to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="bf8f0-110">장치 지원</span><span class="sxs-lookup"><span data-stu-id="bf8f0-110">Device support</span></span>

<span data-ttu-id="bf8f0-111">입력된 모델</span><span class="sxs-lookup"><span data-stu-id="bf8f0-111">Input model</span></span> | [<span data-ttu-id="bf8f0-112">HoloLens (첫 번째 범용)</span><span class="sxs-lookup"><span data-stu-id="bf8f0-112">HoloLens (1st gen)</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details) | <span data-ttu-id="bf8f0-113">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="bf8f0-113">HoloLens 2</span></span> | [<span data-ttu-id="bf8f0-114">몰입 형 헤드셋</span><span class="sxs-lookup"><span data-stu-id="bf8f0-114">Immersive headsets</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details) |
| ---------| -----| ----- | ---------|
<span data-ttu-id="bf8f0-115">지점 및 실습을 사용 하 여 커밋</span><span class="sxs-lookup"><span data-stu-id="bf8f0-115">Point and commit with hands</span></span> | <span data-ttu-id="bf8f0-116">지원 되지 않습니다 ❌</span><span class="sxs-lookup"><span data-stu-id="bf8f0-116">❌ Not supported</span></span> | <span data-ttu-id="bf8f0-117">권장 ✔️</span><span class="sxs-lookup"><span data-stu-id="bf8f0-117">✔️ Recommended</span></span> | <span data-ttu-id="bf8f0-118">권장 ✔️</span><span class="sxs-lookup"><span data-stu-id="bf8f0-118">✔️ Recommended</span></span>

<span data-ttu-id="bf8f0-119">지점 및 커밋 라고도 바늘까지 중 하나인 새 명확 하 고 직접 추적 시스템을 활용 하는 새로운 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-119">Point and commit, also known as hands far, is one of the new features that utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="bf8f0-120">이 입력된 모델 동작 컨트롤러를 사용 하 여 몰입 형 헤드셋에서 기본 입력된 모델 이기도합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-120">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span>

## <a name="hand-rays"></a><span data-ttu-id="bf8f0-121">직접 표면이</span><span class="sxs-lookup"><span data-stu-id="bf8f0-121">Hand rays</span></span>

<span data-ttu-id="bf8f0-122">HoloLens 2에는 팜의 가운데에서 발사 직접 광선을 만들었습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-122">On HoloLens 2, we created a hand ray that shoots out from the center of a palm.</span></span> <span data-ttu-id="bf8f0-123">이 광선 손 모양 아이콘이의 확장으로 취급 됩니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-123">This ray is treated as an extension of the hand.</span></span> <span data-ttu-id="bf8f0-124">도넛 모양 커서는 대상 개체를 사용 하 여 광선과 교차 하는 위치를 나타내는 광선의 끝에 연결 됩니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-124">A donut-shaped cursor is attached to the end of the ray to indicate the location where the ray intersects with a target object.</span></span> <span data-ttu-id="bf8f0-125">그런 다음 커서에서 도착 하는 개체에서 손 모양 아이콘이 gestural 명령의 받을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-125">The object that the cursor lands on can then receive gestural commands from the hand.</span></span>

<span data-ttu-id="bf8f0-126">엄지와 집게 손가락 어 탭 작업을 수행 하 여이 기본 gestural 명령은 트리거됩니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-126">This basic gestural command is triggered by using the thumb and index finger to perform the air-tap action.</span></span> <span data-ttu-id="bf8f0-127">직접 광선 가리키고 어 탭을 커밋를 사용 하 여 사용자가 단추 또는 하이퍼링크는 웹 콘텐츠를 활성화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-127">By using the hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="bf8f0-128">자세한 복합 제스처를 사용 하 여 사용자가 웹 콘텐츠를 탐색 하 고 거리에서 3D 개체를 조작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-128">With more composite gestures, users are capable of navigating web content and manipulating 3D objects from a distance.</span></span> <span data-ttu-id="bf8f0-129">이러한 지점 및 커밋 상태를 설명 하 고 아래 표시 된 것으로 직접 광선의 시각적 디자인도 대응 해야:</span><span class="sxs-lookup"><span data-stu-id="bf8f0-129">The visual design of the hand ray should also react to these point and commit states, as described and shown below:</span></span> 

* <span data-ttu-id="bf8f0-130">에 *가리키는* 상태 이면 광선이 파선 이며 커서 도넛 모양입니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-130">In the *pointing* state, the ray is a dash line and the cursor is a donut shape.</span></span>
* <span data-ttu-id="bf8f0-131">에 *커밋* 상태 이면 광선이 실선으로 바뀌고 커서 점으로 축소 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-131">In the *commit* state, the ray turns into a solid line and the cursor shrinks to a dot.</span></span>

![](images/Hand-Rays-720px.jpg)

## <a name="transition-between-near-and-far"></a><span data-ttu-id="bf8f0-132">거의 및 끝 사이 전환</span><span class="sxs-lookup"><span data-stu-id="bf8f0-132">Transition between near and far</span></span>

<span data-ttu-id="bf8f0-133">"집게 손가락으로 가리키는"와 같은 특정 제스처를 사용 하는 대신 아웃 손바닥을 해제 하 고 자세한 조작 제스처에 대 한 5 개의 손가락 예약의 가운데에서와 같은 축소 이동해 서 오는 광선 설계 했습니다 광선과 보내도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-133">Instead of using specific gesture, such as "pointing with index finger" to direct the ray, we designed the ray coming out from the center of the palm, releasing and reserving the five fingers for more manipulative gestures, such as pinch and grab.</span></span> <span data-ttu-id="bf8f0-134">이 디자인을 만들겠습니다. 멘 탈 모델 하나만 근거리 및 원거리 상호 작용에 대 한 손 제스처의 동일한 집합에 정확 하 게 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-134">With this design, we create only one mental model, supporting exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="bf8f0-135">다른 거리에 있는 개체를 조작 하는 동일한 잡기 제스처를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-135">You can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="bf8f0-136">방사선 호출에는 자동 및 근접 기반입니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-136">The invocation of the rays is automatic and proximity based:</span></span>

*  <span data-ttu-id="bf8f0-137">개체 내의 거리 (약 50 cm)에 도달 하는 arm 경우 방사선 거의 상호 작용에 대 한 장려 자동으로 해제 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-137">When an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span>
*  <span data-ttu-id="bf8f0-138">개체가 50 cm 보다 더 강력 하 고 방사선 켜 집니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-138">When the object is farther than 50 cm, the rays are turned on.</span></span> <span data-ttu-id="bf8f0-139">원활 하 게 전환 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-139">The transition should be smooth and seamless.</span></span>

![](images/Transition-Between-Near-And-Far-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="bf8f0-140">2D 슬레이트 상호 작용</span><span class="sxs-lookup"><span data-stu-id="bf8f0-140">2D slate interaction</span></span>

<span data-ttu-id="bf8f0-141">2D 슬레이트는 holographic 컨테이너 2D 앱 콘텐츠를 웹 브라우저와 같은 호스팅.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-141">A 2D Slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="bf8f0-142">훨씬 2D 슬레이트를 상호 작용 하기 위한 디자인 개념 직접 광선 대상 및 air tap를 사용 하 여 선택 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-142">The design concept for far interacting with a 2D slate is to use hand rays to target and air tap to select.</span></span> <span data-ttu-id="bf8f0-143">을 대상으로 하는 직접 빛을 사용 하 여 후 사용자에 어 탭을 하이퍼링크 또는 단추를 트리거할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-143">After targeting with a hand ray, users can air tap to trigger a hyperlink or a button.</span></span> <span data-ttu-id="bf8f0-144">한편 "누르기 및 끌기 어" 하는 데 사용할 수 슬레이트 콘텐츠를 아래로 스크롤합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-144">They can use one hand to "air tap and drag" to scroll a slate content up and down.</span></span> <span data-ttu-id="bf8f0-145">두 손을 사용 하 여 탭 하 고 끌어서 어 상대적 동작에 슬레이트 콘텐츠 확대할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-145">The relative motion of using two hands to air tap and drag can zoom in and out the slate content.</span></span>

<span data-ttu-id="bf8f0-146">모서리와 가장자리에 직접 광선을 대상으로 하는 가장 가까운 조작 유도성을 표시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-146">Targeting the hand ray at the corners and edges reveals the closest manipulation affordance.</span></span> <span data-ttu-id="bf8f0-147">"잡기, 끌기" 조작 affordances, 사용자가 수행할 수 있습니다 uniform 모퉁이 affordances 통해 크기 조정 및 edge affordances 통해 슬레이트 원래 대로 되돌릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-147">By "grab and drag" the manipulation affordances, users can perform uniform scaling through the corner affordances and can reflow the slate via the edge affordances.</span></span> <span data-ttu-id="bf8f0-148">2D 슬레이트의 맨 위에 있는 holobar 위치와 방향을 잃기 사용자가 이동할 수 전체 슬레이트입니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-148">Grabbing and dragging the holobar at the top of the 2D slate can users move the whole slate.</span></span>

![](images/2D-Slate-Interaction-Far-720px.jpg)

<span data-ttu-id="bf8f0-149">2D 조작 하기 위한 자체를 슬레이트:</span><span class="sxs-lookup"><span data-stu-id="bf8f0-149">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="bf8f0-150">사용자가 직접 광선 모퉁이 또는 가장자리를 가장 가까운 조작 유도성 표시를 가리킵니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-150">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="bf8f0-151">유도성에서 조작 제스처를 적용 하 여 사용자 모퉁이 유도성 통해 균일 한 크기 조정을 수행할 수 있습니다 및 edge 유도성 통해 슬레이트 원래 대로 되돌릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-151">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="bf8f0-152">2D 슬레이트의 맨 위에 있는 holobar에서 조작 제스처를 적용 하 여 사용자가 전체 슬레이트를 이동할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-152">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="bf8f0-153">3D 개체 조작</span><span class="sxs-lookup"><span data-stu-id="bf8f0-153">3D object manipulation</span></span>

<span data-ttu-id="bf8f0-154">직접 조작에서 3D 개체를 조작 유도성 기반 및 비 유도성 기반된 조작을 조작 하는 사용자는 두 가지 방법이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-154">In direct manipulation, there are two ways for users to manipulate 3D object, affordance-based manipulation and non-affordance based manipulation.</span></span> <span data-ttu-id="bf8f0-155">지점 및 커밋 모델에서 사용자 정확 하 게 직접 광선을 통해 동일한 작업을 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-155">In the point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="bf8f0-156">필요 없는 추가 학습 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-156">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="bf8f0-157">유도성 기반 조작</span><span class="sxs-lookup"><span data-stu-id="bf8f0-157">Affordance-based manipulation</span></span>
<span data-ttu-id="bf8f0-158">사용자는 가리키고 조작 affordances 고 경계 상자를 표시 합니다. 직접 광선을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-158">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="bf8f0-159">사용자는 전체 개체를 이동 하는 경계 상자에, 회전 하려면 edge affordances 및 조작 제스처를 적용할 수 있습니다는 coner affordances 균일 하 게 확장 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-159">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="bf8f0-160">비-유도성 기반된 조작</span><span class="sxs-lookup"><span data-stu-id="bf8f0-160">Non-affordance based manipulation</span></span>
<span data-ttu-id="bf8f0-161">사용자가 직접 광선 경계 상자를 표시 하 고 직접 조작 제스처에서 적용을 사용 하 여 가리킵니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-161">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="bf8f0-162">한 손으로 번역 및 회전 개체의 동작 및 손 모양 아이콘이의 방향에 연결 됩니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-162">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="bf8f0-163">두 손을 사용 하 여 사용자가 변환, 확장할 수 있으며 두 손의 상대적 동작에 따라 회전 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-163">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="bf8f0-164">Instinctual gesturers</span><span class="sxs-lookup"><span data-stu-id="bf8f0-164">Instinctual gesturers</span></span>
<span data-ttu-id="bf8f0-165">지점 및 커밋에 대 한 instinctual 제스처 개념이 비슷합니다를 직접 조작 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-165">The concept of instinctual gestures for point and commit is similar to that for direct manipulation.</span></span> <span data-ttu-id="bf8f0-166">사용자는 3D 개체에 대해 수행할 가정 제스처 UI affordances의 디자인 지침을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-166">The gestures users are suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="bf8f0-167">예를 들어 작은 제어 지점 사용자가 사용자가 모든 5 개의 손가락을 사용 하 여 더 큰 개체를 얻을 수도 있지만 해당 엄지와 집게 손가락 손가락 모으기 동기를 부여 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-167">For example, a small control point might motivate users to pinch with their thumb and index finger, while a user might want to grab a larger object using all 5 fingers.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="bf8f0-168">실습 6 DoF 컨트롤러 사이의 대칭 디자인</span><span class="sxs-lookup"><span data-stu-id="bf8f0-168">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="bf8f0-169">처음에 지점 및 끝 상호 작용에 대 한 커밋 개념이 생성 되어에 대 한는 혼합 현실 포털 (MRP), 사용자는 몰입 형 헤드셋 마모 되 고 상호 작용 하는 컨트롤러 동작을 통해 3D 개체를 사용 하 여 위치를 정의 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-169">The concept of point and commit for far interaction was initially created and defined for the Mixed Reality Portal (MRP), where a user wears an immersive headset and interacts with 3D objects via motion controllers.</span></span> <span data-ttu-id="bf8f0-170">동작 컨트롤러 가리키고 먼 개체 조작에 대 한 광선 아웃 문제를 해결 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-170">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="bf8f0-171">더 다양 한 작업을 커밋에 대 한 컨트롤러에는 단추가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-171">There are buttons on the controllers for further committing different actions.</span></span> <span data-ttu-id="bf8f0-172">광선의 상호 작용 모델을 활용 하 고 양쪽 손으로에 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-172">We leverage the interaction model of rays and attached them to both hands.</span></span> <span data-ttu-id="bf8f0-173">이 대칭 디자인 MRP에 익숙한 사용자 HoloLen 2를 사용할 때 훨씬 가리키는 및 조작에 대 한 다른 상호 작용 모델에 알아보려면 필요가 그 반대로 가능 합니다.</span><span class="sxs-lookup"><span data-stu-id="bf8f0-173">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation when they use HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>

## <a name="instinctual-gestures"></a><span data-ttu-id="bf8f0-174">Instinctual 제스처</span><span class="sxs-lookup"><span data-stu-id="bf8f0-174">Instinctual gestures</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)

## <a name="see-also"></a><span data-ttu-id="bf8f0-175">참조</span><span class="sxs-lookup"><span data-stu-id="bf8f0-175">See also</span></span>
* [<span data-ttu-id="bf8f0-176">헤드 게이즈 및 커밋</span><span class="sxs-lookup"><span data-stu-id="bf8f0-176">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="bf8f0-177">수동으로 직접 조작</span><span class="sxs-lookup"><span data-stu-id="bf8f0-177">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="bf8f0-178">Instinctual 상호 작용</span><span class="sxs-lookup"><span data-stu-id="bf8f0-178">Instinctual interactions</span></span>](interaction-fundamentals.md)

