---
title: 위치를 찾을 수 있는 카메라
description: HoloLens front camera 카메라, 작동 방식 및 개발자가 사용할 수 있는 프로필 및 해상도에 대 한 일반 정보입니다.
author: cdedmonds
ms.author: wguyman
ms.date: 06/12/2019
ms.topic: article
keywords: 카메라, hololens, 컬러 카메라, 전면, hololens 2, cv, 컴퓨터 비전, fiducial, 표식, qr 코드, qr, 사진, 비디오
ms.openlocfilehash: e158eb2e708164cbd68620f3f46d3039c2eaa730
ms.sourcegitcommit: 4282d92e93869e4829338bdf7d981c3ee0260bfd
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/23/2020
ms.locfileid: "85216224"
---
# <a name="locatable-camera"></a><span data-ttu-id="69dc9-104">위치를 찾을 수 있는 카메라</span><span class="sxs-lookup"><span data-stu-id="69dc9-104">Locatable camera</span></span>

<span data-ttu-id="69dc9-105">HoloLens는 장치 전면에 탑재 된 세계 카메라를 포함 하 여 앱이 사용자에 게 표시 되는 내용을 볼 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-105">HoloLens includes a world-facing camera mounted on the front of the device, which enables apps to see what the user sees.</span></span> <span data-ttu-id="69dc9-106">개발자는 스마트폰, 노트북 또는 데스크톱에서 색 카메라를 사용할 때와 마찬가지로 카메라에 액세스 하 고 해당 카메라를 제어할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-106">Developers have access to and control of the camera, just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="69dc9-107">모바일 및 데스크톱에서 작동 하는 동일한 유니버설 windows [미디어 캡처](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) 및 windows Media foundation Api는 HoloLens에서 작업 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="69dc9-108">또한 Unity는 일반적인 사진과 비디오 (holograms 유무에 관계 없이)를 사용 하 고 카메라의 위치와 장면의 원근감을 찾는 등의 작업을 위해 HoloLens에서 카메라의 간단한 사용을 추상화 하도록 [이러한 Windows api를 래핑 했습니다](locatable-camera-in-unity.md) .</span><span class="sxs-lookup"><span data-stu-id="69dc9-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="69dc9-109">장치 카메라 정보</span><span class="sxs-lookup"><span data-stu-id="69dc9-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="69dc9-110">HoloLens (첫 번째 생성)</span><span class="sxs-lookup"><span data-stu-id="69dc9-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="69dc9-111">자동 흰색 잔액, 자동 노출 및 전체 이미지 처리 파이프라인이 있는 PV (focus photo/video) 카메라</span><span class="sxs-lookup"><span data-stu-id="69dc9-111">Fixed focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="69dc9-112">카메라가 활성화 될 때마다 전 세계의 개인 개인 정보 취급 LED가 켜 집니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="69dc9-113">카메라는 30, 24, 20, 15, 5fps의 다음 모드 (모든 모드에서 16:9 가로 세로 비율)를 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="69dc9-114">동영상</span><span class="sxs-lookup"><span data-stu-id="69dc9-114">Video</span></span>  |  <span data-ttu-id="69dc9-115">미리 보기</span><span class="sxs-lookup"><span data-stu-id="69dc9-115">Preview</span></span>  |  <span data-ttu-id="69dc9-116">실패할</span><span class="sxs-lookup"><span data-stu-id="69dc9-116">Still</span></span>  |  <span data-ttu-id="69dc9-117">뷰의 가로 필드 (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="69dc9-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="69dc9-118">권장 사용법</span><span class="sxs-lookup"><span data-stu-id="69dc9-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="69dc9-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-119">1280x720</span></span> |  <span data-ttu-id="69dc9-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-120">1280x720</span></span> |  <span data-ttu-id="69dc9-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-121">1280x720</span></span> |  <span data-ttu-id="69dc9-122">45deg</span><span class="sxs-lookup"><span data-stu-id="69dc9-122">45deg</span></span>  |  <span data-ttu-id="69dc9-123">(비디오 안정화를 사용 하는 기본 모드)</span><span class="sxs-lookup"><span data-stu-id="69dc9-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="69dc9-124">해당 없음</span><span class="sxs-lookup"><span data-stu-id="69dc9-124">N/A</span></span> |  <span data-ttu-id="69dc9-125">해당 없음</span><span class="sxs-lookup"><span data-stu-id="69dc9-125">N/A</span></span> |  <span data-ttu-id="69dc9-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="69dc9-126">2048x1152</span></span> |  <span data-ttu-id="69dc9-127">67deg</span><span class="sxs-lookup"><span data-stu-id="69dc9-127">67deg</span></span> |  <span data-ttu-id="69dc9-128">가장 높은 해상도의 이미지</span><span class="sxs-lookup"><span data-stu-id="69dc9-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="69dc9-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="69dc9-129">1408x792</span></span> |  <span data-ttu-id="69dc9-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="69dc9-130">1408x792</span></span> |  <span data-ttu-id="69dc9-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="69dc9-131">1408x792</span></span> |  <span data-ttu-id="69dc9-132">48deg</span><span class="sxs-lookup"><span data-stu-id="69dc9-132">48deg</span></span> |  <span data-ttu-id="69dc9-133">비디오 안정화 전 Overscan (패딩) 해상도</span><span class="sxs-lookup"><span data-stu-id="69dc9-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="69dc9-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="69dc9-134">1344x756</span></span> |  <span data-ttu-id="69dc9-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="69dc9-135">1344x756</span></span> |  <span data-ttu-id="69dc9-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="69dc9-136">1344x756</span></span> |  <span data-ttu-id="69dc9-137">67deg</span><span class="sxs-lookup"><span data-stu-id="69dc9-137">67deg</span></span> |  <span data-ttu-id="69dc9-138">Overscan를 사용 하는 넓은 FOV 비디오 모드</span><span class="sxs-lookup"><span data-stu-id="69dc9-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="69dc9-139">896x504</span><span class="sxs-lookup"><span data-stu-id="69dc9-139">896x504</span></span> |  <span data-ttu-id="69dc9-140">896x504</span><span class="sxs-lookup"><span data-stu-id="69dc9-140">896x504</span></span> |  <span data-ttu-id="69dc9-141">896x504</span><span class="sxs-lookup"><span data-stu-id="69dc9-141">896x504</span></span> |  <span data-ttu-id="69dc9-142">48deg</span><span class="sxs-lookup"><span data-stu-id="69dc9-142">48deg</span></span> |  <span data-ttu-id="69dc9-143">이미지 처리 작업에 대 한 낮은 전원/저해상도 모드</span><span class="sxs-lookup"><span data-stu-id="69dc9-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="69dc9-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="69dc9-144">HoloLens 2</span></span>

* <span data-ttu-id="69dc9-145">자동 흰색 잔액, 자동 노출 및 전체 이미지 처리 파이프라인이 있는 PV (자동 포커스 사진/비디오) 카메라</span><span class="sxs-lookup"><span data-stu-id="69dc9-145">Auto-focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="69dc9-146">카메라가 활성화 될 때마다 전 세계의 개인 개인 정보 취급 LED가 켜 집니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-146">White Privacy LED facing the world will illuminate whenever the camera is active.</span></span>
* <span data-ttu-id="69dc9-147">HoloLens 2는 다른 카메라 프로필을 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-147">HoloLens 2 supports different camera profiles.</span></span> <span data-ttu-id="69dc9-148">[카메라 기능을 검색 하 고 선택](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles)하는 방법을 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-148">Learn how to [discover and select camera capabilities](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span></span>
* <span data-ttu-id="69dc9-149">카메라는 다음 프로필 및 해상도를 지원 합니다 (모든 비디오 모드는 16:9 가로 세로 비율).</span><span class="sxs-lookup"><span data-stu-id="69dc9-149">The camera supports the following profiles and resolutions (all video modes are 16:9 aspect ratio):</span></span>
  
  | <span data-ttu-id="69dc9-150">프로필</span><span class="sxs-lookup"><span data-stu-id="69dc9-150">Profile</span></span>                                         | <span data-ttu-id="69dc9-151">동영상</span><span class="sxs-lookup"><span data-stu-id="69dc9-151">Video</span></span>     | <span data-ttu-id="69dc9-152">미리 보기</span><span class="sxs-lookup"><span data-stu-id="69dc9-152">Preview</span></span>   | <span data-ttu-id="69dc9-153">실패할</span><span class="sxs-lookup"><span data-stu-id="69dc9-153">Still</span></span>     | <span data-ttu-id="69dc9-154">프레임 속도</span><span class="sxs-lookup"><span data-stu-id="69dc9-154">Frame rates</span></span> | <span data-ttu-id="69dc9-155">뷰의 가로 필드 (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="69dc9-155">Horizontal Field of View (H-FOV)</span></span> | <span data-ttu-id="69dc9-156">권장 사용법</span><span class="sxs-lookup"><span data-stu-id="69dc9-156">Suggested usage</span></span>                             |
  |-------------------------------------------------|-----------|-----------|-----------|-------------|----------------------------------|---------------------------------------------|
  | <span data-ttu-id="69dc9-157">레거시, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="69dc9-157">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="69dc9-158">2272x1278</span><span class="sxs-lookup"><span data-stu-id="69dc9-158">2272x1278</span></span> | <span data-ttu-id="69dc9-159">2272x1278</span><span class="sxs-lookup"><span data-stu-id="69dc9-159">2272x1278</span></span> |           | <span data-ttu-id="69dc9-160">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-160">15,30</span></span>       | <span data-ttu-id="69dc9-161">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-161">64.69</span></span>                            | <span data-ttu-id="69dc9-162">고품질 비디오 녹화</span><span class="sxs-lookup"><span data-stu-id="69dc9-162">High quality video recording</span></span>                |
  | <span data-ttu-id="69dc9-163">레거시, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="69dc9-163">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="69dc9-164">896x504</span><span class="sxs-lookup"><span data-stu-id="69dc9-164">896x504</span></span>   | <span data-ttu-id="69dc9-165">896x504</span><span class="sxs-lookup"><span data-stu-id="69dc9-165">896x504</span></span>   |           | <span data-ttu-id="69dc9-166">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-166">15,30</span></span>       | <span data-ttu-id="69dc9-167">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-167">64.69</span></span>                            | <span data-ttu-id="69dc9-168">고품질 사진 캡처에 대 한 미리 보기 스트림</span><span class="sxs-lookup"><span data-stu-id="69dc9-168">Preview stream for high quality photo capture</span></span> |
  | <span data-ttu-id="69dc9-169">레거시, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="69dc9-169">Legacy,0  BalancedVideoAndPhoto,100</span></span>             |           |           | <span data-ttu-id="69dc9-170">3904x2196</span><span class="sxs-lookup"><span data-stu-id="69dc9-170">3904x2196</span></span> |             | <span data-ttu-id="69dc9-171">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-171">64.69</span></span>                            | <span data-ttu-id="69dc9-172">고품질 사진 캡처</span><span class="sxs-lookup"><span data-stu-id="69dc9-172">High quality photo capture</span></span>                  |
  | <span data-ttu-id="69dc9-173">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-173">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="69dc9-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-174">1952x1100</span></span> | <span data-ttu-id="69dc9-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-175">1952x1100</span></span> | <span data-ttu-id="69dc9-176">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-176">1952x1100</span></span> | <span data-ttu-id="69dc9-177">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-177">15,30</span></span>       | <span data-ttu-id="69dc9-178">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-178">64.69</span></span>                            | <span data-ttu-id="69dc9-179">긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-179">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="69dc9-180">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-180">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="69dc9-181">1504x846</span><span class="sxs-lookup"><span data-stu-id="69dc9-181">1504x846</span></span>  | <span data-ttu-id="69dc9-182">1504x846</span><span class="sxs-lookup"><span data-stu-id="69dc9-182">1504x846</span></span>  |           | <span data-ttu-id="69dc9-183">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-183">15,30</span></span>       | <span data-ttu-id="69dc9-184">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-184">64.69</span></span>                            | <span data-ttu-id="69dc9-185">긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-185">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="69dc9-186">비디오 회의, 100</span><span class="sxs-lookup"><span data-stu-id="69dc9-186">VideoConferencing,100</span></span>                           | <span data-ttu-id="69dc9-187">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-187">1952x1100</span></span> | <span data-ttu-id="69dc9-188">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-188">1952x1100</span></span> | <span data-ttu-id="69dc9-189">1952x1100</span><span class="sxs-lookup"><span data-stu-id="69dc9-189">1952x1100</span></span> | <span data-ttu-id="69dc9-190">15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="69dc9-190">15,30,60</span></span>    | <span data-ttu-id="69dc9-191">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-191">64.69</span></span>                            | <span data-ttu-id="69dc9-192">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-192">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-193">비디오 회의, 100</span><span class="sxs-lookup"><span data-stu-id="69dc9-193">Videoconferencing,100</span></span>                           | <span data-ttu-id="69dc9-194">1504x846</span><span class="sxs-lookup"><span data-stu-id="69dc9-194">1504x846</span></span>  | <span data-ttu-id="69dc9-195">1504x846</span><span class="sxs-lookup"><span data-stu-id="69dc9-195">1504x846</span></span>  |           | <span data-ttu-id="69dc9-196">5, 15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="69dc9-196">5,15,30,60</span></span>  | <span data-ttu-id="69dc9-197">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-197">64.69</span></span>                            | <span data-ttu-id="69dc9-198">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-198">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-199">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-199">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-200">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="69dc9-200">1920x1080</span></span> | <span data-ttu-id="69dc9-201">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="69dc9-201">1920x1080</span></span> | <span data-ttu-id="69dc9-202">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="69dc9-202">1920x1080</span></span> | <span data-ttu-id="69dc9-203">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-203">15,30</span></span>       | <span data-ttu-id="69dc9-204">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-204">64.69</span></span>                            | <span data-ttu-id="69dc9-205">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-205">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-206">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-206">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-207">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-207">1280x720</span></span>  | <span data-ttu-id="69dc9-208">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-208">1280x720</span></span>  | <span data-ttu-id="69dc9-209">1280x720</span><span class="sxs-lookup"><span data-stu-id="69dc9-209">1280x720</span></span>  | <span data-ttu-id="69dc9-210">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-210">15,30</span></span>       | <span data-ttu-id="69dc9-211">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-211">64.69</span></span>                            | <span data-ttu-id="69dc9-212">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-212">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-213">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-213">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-214">1128x636</span><span class="sxs-lookup"><span data-stu-id="69dc9-214">1128x636</span></span>  |           |           | <span data-ttu-id="69dc9-215">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-215">15,30</span></span>       | <span data-ttu-id="69dc9-216">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-216">64.69</span></span>                            | <span data-ttu-id="69dc9-217">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-217">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-218">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-218">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-219">960 x 540</span><span class="sxs-lookup"><span data-stu-id="69dc9-219">960x540</span></span>   |           |           | <span data-ttu-id="69dc9-220">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-220">15,30</span></span>       | <span data-ttu-id="69dc9-221">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-221">64.69</span></span>                            | <span data-ttu-id="69dc9-222">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-222">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-223">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-223">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-224">760x428</span><span class="sxs-lookup"><span data-stu-id="69dc9-224">760x428</span></span>   |           |           | <span data-ttu-id="69dc9-225">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-225">15,30</span></span>       | <span data-ttu-id="69dc9-226">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-226">64.69</span></span>                            | <span data-ttu-id="69dc9-227">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-227">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-228">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-228">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-229">640x360</span><span class="sxs-lookup"><span data-stu-id="69dc9-229">640x360</span></span>   |           |           | <span data-ttu-id="69dc9-230">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-230">15,30</span></span>       | <span data-ttu-id="69dc9-231">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-231">64.69</span></span>                            | <span data-ttu-id="69dc9-232">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-232">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-233">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-233">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-234">500x282</span><span class="sxs-lookup"><span data-stu-id="69dc9-234">500x282</span></span>   |           |           | <span data-ttu-id="69dc9-235">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-235">15,30</span></span>       | <span data-ttu-id="69dc9-236">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-236">64.69</span></span>                            | <span data-ttu-id="69dc9-237">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-237">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="69dc9-238">비디오 회의, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="69dc9-238">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="69dc9-239">424x240</span><span class="sxs-lookup"><span data-stu-id="69dc9-239">424x240</span></span>   |           |           | <span data-ttu-id="69dc9-240">15, 30</span><span class="sxs-lookup"><span data-stu-id="69dc9-240">15,30</span></span>       | <span data-ttu-id="69dc9-241">64.69</span><span class="sxs-lookup"><span data-stu-id="69dc9-241">64.69</span></span>                            | <span data-ttu-id="69dc9-242">비디오 회의, 긴 기간 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-242">Video conferencing, long duration scenarios</span></span> |

>[!NOTE]
><span data-ttu-id="69dc9-243">고객은 [혼합 현실 캡처](mixed-reality-capture.md) 를 활용 하 여 holograms 및 비디오 안정화를 포함 하는 앱의 비디오 또는 사진을 찍을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-243">Customers can leverage [mixed reality capture](mixed-reality-capture.md) to take videos or photos of your app, which include holograms and video stabilization.</span></span>
>
><span data-ttu-id="69dc9-244">개발자는 응용 프로그램을 만들 때 고객이 콘텐츠를 캡처할 때 최대한 적절 하 게 보이도록 하려는 경우 고려해 야 할 사항이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-244">As a developer, there are considerations you should take into account when creating your app if you want it to look as good as possible when a customer captures content.</span></span> <span data-ttu-id="69dc9-245">앱 내에서 직접 혼합 현실 캡처를 사용 하도록 설정 (및 사용자 지정) 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-245">You can also enable (and customize) mixed reality capture from directly within your app.</span></span> <span data-ttu-id="69dc9-246">[개발자를 위한 혼합 현실 캡처에서](mixed-reality-capture-for-developers.md)자세히 알아보세요.</span><span class="sxs-lookup"><span data-stu-id="69dc9-246">Learn more at [mixed reality capture for developers](mixed-reality-capture-for-developers.md).</span></span>

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="69dc9-247">전 세계에서 장치 카메라 찾기</span><span class="sxs-lookup"><span data-stu-id="69dc9-247">Locating the Device Camera in the World</span></span>

<span data-ttu-id="69dc9-248">HoloLens에서 사진과 비디오를 사용 하는 경우 캡처된 프레임에는 카메라의 렌즈 모델 뿐만 아니라 전 세계의 카메라 위치가 포함 됩니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-248">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="69dc9-249">이를 통해 응용 프로그램은 확대 된 이미징 시나리오에 대 한 실제 환경에서 카메라의 위치를 지정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-249">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="69dc9-250">개발자는 선호 하는 이미지 처리 또는 사용자 지정 컴퓨터 비전 라이브러리를 사용 하 여 자신의 시나리오를 창의적 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-250">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="69dc9-251">HoloLens 설명서의 다른 곳에서 "카메라"는 "가상 게임 카메라" (앱에서 렌더링 하는 것과 같은)를 참조할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-251">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="69dc9-252">달리 지정 되지 않은 경우이 페이지의 "카메라"는 실제 RGB 색 카메라를 참조 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-252">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

### <a name="using-unity"></a><span data-ttu-id="69dc9-253">Unity 사용</span><span class="sxs-lookup"><span data-stu-id="69dc9-253">Using Unity</span></span>

<span data-ttu-id="69dc9-254">' CameraIntrinsics ' 및 ' CameraCoordinateSystem '에서 응용 프로그램/세계 좌표계로 이동 하려면 [Unity의 과정이 카메라](locatable-camera-in-unity.md) 문서에 있는 지침을 따르세요.</span><span class="sxs-lookup"><span data-stu-id="69dc9-254">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, follow the instructions in the [Locatable camera in Unity](locatable-camera-in-unity.md) article.</span></span>  <span data-ttu-id="69dc9-255">CameraToWorldMatrix는 PhotoCaptureFrame 클래스에서 자동으로 제공 되므로 아래에서 설명 하는 CameraCoordinateSystem 변환에 대해 걱정할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-255">CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class, and so you don't need to worry about the CameraCoordinateSystem transforms discussed below.</span></span>

### <a name="using-mediaframereference"></a><span data-ttu-id="69dc9-256">MediaFrameReference 사용</span><span class="sxs-lookup"><span data-stu-id="69dc9-256">Using MediaFrameReference</span></span>

<span data-ttu-id="69dc9-257">이러한 지침은 [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) 클래스를 사용 하 여 카메라에서 이미지 프레임을 읽는 경우에 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-257">These instructions apply if you are using the [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) class to read image frames from the camera.</span></span>

<span data-ttu-id="69dc9-258">각 이미지 프레임 (사진 또는 비디오)에는 캡처 시점에 카메라를 기반으로 하는 [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) 이 포함 되어 있으며,이는 [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference)의 [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) 속성을 사용 하 여 액세스할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-258">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture, which can be accessed using the [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="69dc9-259">또한 각 프레임에는 [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) 속성에서 찾을 수 있는 카메라 렌즈 모델에 대 한 설명이 포함 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-259">In addition, each frame contains a description of the camera lens model, which can be found in the [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="69dc9-260">이러한 변환은 함께 각 픽셀에 대해 픽셀을 생성 한 photons에서 가져온 경로를 나타내는 3D 공간의 광선을 정의 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-260">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="69dc9-261">이러한 광선은 프레임의 좌표계에서 다른 좌표계 (예: [고정 참조 프레임](coordinate-systems.md#stationary-frame-of-reference))로 변환을 가져와서 앱의 다른 콘텐츠와 관련 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-261">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="69dc9-262">요약 하자면, 각 이미지 프레임은 다음을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-262">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="69dc9-263">픽셀 데이터 (RGB/NV12/JPEG/등 형식)</span><span class="sxs-lookup"><span data-stu-id="69dc9-263">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="69dc9-264">캡처 위치의 [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem)</span><span class="sxs-lookup"><span data-stu-id="69dc9-264">A [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="69dc9-265">카메라의 렌즈 모드가 포함 된 [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) 클래스입니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-265">A [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

<span data-ttu-id="69dc9-266">[HolographicFaceTracking 샘플](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) 에서는 카메라의 좌표계와 사용자 고유의 응용 프로그램 좌표계 간에 변환을 쿼리 하는 매우 간단한 방법을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-266">The [HolographicFaceTracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate systems.</span></span>

### <a name="using-media-foundation"></a><span data-ttu-id="69dc9-267">미디어 파운데이션 사용</span><span class="sxs-lookup"><span data-stu-id="69dc9-267">Using Media Foundation</span></span>

<span data-ttu-id="69dc9-268">카메라에서 이미지 프레임을 읽기 위해 미디어 파운데이션를 직접 사용 하는 경우 다음 샘플 코드에 표시 된 것 처럼 각 프레임의 [MFSampleExtension_CameraExtrinsics 특성](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) 및 [MFSampleExtension_PinholeCameraIntrinsics 특성](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) 을 사용 하 여 응용 프로그램의 다른 좌표계를 기준으로 카메라 프레임을 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-268">If you are using Media Foundation directly to read image frames from the camera, you can use each frame's [MFSampleExtension_CameraExtrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) and [MFSampleExtension_PinholeCameraIntrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) to locate camera frames relative to your application's other coordinate systems, as shown in this sample code:</span></span>

```cpp
#include <winrt/windows.perception.spatial.preview.h>
#include <mfapi.h>
#include <mfidl.h>
 
using namespace winrt::Windows::Foundation;
using namespace winrt::Windows::Foundation::Numerics;
using namespace winrt::Windows::Perception;
using namespace winrt::Windows::Perception::Spatial;
using namespace winrt::Windows::Perception::Spatial::Preview;
 
class CameraFrameLocator
{
public:
    struct CameraFrameLocation
    {
        SpatialCoordinateSystem CoordinateSystem;
        float4x4 CameraViewToCoordinateSytemTransform;
        MFPinholeCameraIntrinsics Intrinsics;
    };
 
    std::optional<CameraFrameLocation> TryLocateCameraFrame(IMFSample* pSample)
    {
        MFCameraExtrinsics cameraExtrinsics;
        MFPinholeCameraIntrinsics cameraIntrinsics;
        UINT32 sizeCameraExtrinsics = 0;
        UINT32 sizeCameraIntrinsics = 0;
        UINT64 sampleTimeHns = 0;
 
        // query sample for calibration and validate
        if (FAILED(pSample->GetUINT64(MFSampleExtension_DeviceTimestamp, &sampleTimeHns)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_CameraExtrinsics, (UINT8*)& cameraExtrinsics, sizeof(cameraExtrinsics), &sizeCameraExtrinsics)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_PinholeCameraIntrinsics, (UINT8*)& cameraIntrinsics, sizeof(cameraIntrinsics), &sizeCameraIntrinsics)) ||
            (sizeCameraExtrinsics != sizeof(cameraExtrinsics)) ||
            (sizeCameraIntrinsics != sizeof(cameraIntrinsics)) ||
            (cameraExtrinsics.TransformCount == 0))
        {
            return std::nullopt;
        }
 
        // compute extrinsic transform
        const auto& calibratedTransform = cameraExtrinsics.CalibratedTransforms[0];
        const GUID& dynamicNodeId = calibratedTransform.CalibrationId;
        const float4x4 cameraToDynamicNode =
            make_float4x4_from_quaternion(quaternion{ calibratedTransform.Orientation.x, calibratedTransform.Orientation.y, calibratedTransform.Orientation.z, calibratedTransform.Orientation.w }) *
            make_float4x4_translation(calibratedTransform.Position.x, calibratedTransform.Position.y, calibratedTransform.Position.z);
 
        // update locator cache for dynamic node
        if (dynamicNodeId != m_currentDynamicNodeId || !m_locator)
        {
            m_locator = SpatialGraphInteropPreview::CreateLocatorForNode(dynamicNodeId);
            if (!m_locator)
            {
                return std::nullopt;
            }
 
            m_frameOfReference = m_locator.CreateAttachedFrameOfReferenceAtCurrentHeading();
            m_currentDynamicNodeId = dynamicNodeId;
        }
 
        // locate dynamic node
        auto timestamp = PerceptionTimestampHelper::FromSystemRelativeTargetTime(TimeSpan{ sampleTimeHns });
        auto coordinateSystem = m_frameOfReference.GetStationaryCoordinateSystemAtTimestamp(timestamp);
        auto location = m_locator.TryLocateAtTimestamp(timestamp, coordinateSystem);
        if (!location)
        {
            return std::nullopt;
        }
 
        const float4x4 dynamicNodeToCoordinateSystem = make_float4x4_from_quaternion(location.Orientation()) * make_float4x4_translation(location.Position());
 
        return CameraFrameLocation{ coordinateSystem, cameraToDynamicNode * dynamicNodeToCoordinateSystem, cameraIntrinsics };
    }

private:
    GUID m_currentDynamicNodeId{ GUID_NULL };
    SpatialLocator m_locator{ nullptr };
    SpatialLocatorAttachedFrameOfReference m_frameOfReference{ nullptr };
};
```

### <a name="distortion-error"></a><span data-ttu-id="69dc9-269">왜곡 오류</span><span class="sxs-lookup"><span data-stu-id="69dc9-269">Distortion Error</span></span>

<span data-ttu-id="69dc9-270">HoloLens에서 비디오와 스틸 이미지 스트림은 응용 프로그램에서 프레임을 사용할 수 있게 되기 전에 시스템의 이미지 처리 파이프라인에서 undistorted 됩니다 (미리 보기 스트림은 원래 왜곡 된 프레임을 포함 함).</span><span class="sxs-lookup"><span data-stu-id="69dc9-270">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="69dc9-271">CameraIntrinsics만 사용할 수 있으므로 응용 프로그램은 이미지 프레임이 완벽 한 pinhole 카메라를 나타낸다고 가정 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-271">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera.</span></span>

<span data-ttu-id="69dc9-272">HoloLens (처음 생성)에서 이미지 프로세서의 왜곡 함수는 프레임 메타 데이터에서 CameraIntrinsics를 사용 하는 경우에도 최대 10 픽셀의 오류를 남길 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-272">On HoloLens (first-generation), the undistortion function in the image processor may still leave an error of up to 10 pixels when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="69dc9-273">많은 사용 사례에서이 오류가 발생 하지는 않지만, 예를 들어 실제 세계 포스터/표식에 holograms를 맞추는 경우 10px 오프셋 (holograms의 경우 약 11mm이)을 <확인할 수 있습니다 .이 왜곡 오류가 원인일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-273">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away), this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="69dc9-274">과정이 카메라 사용 시나리오</span><span class="sxs-lookup"><span data-stu-id="69dc9-274">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="69dc9-275">캡처된 전 세계에 사진 또는 비디오 표시</span><span class="sxs-lookup"><span data-stu-id="69dc9-275">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="69dc9-276">장치 카메라 프레임에는 이미지를 찍은 시간을 정확히 표시 하는 데 사용할 수 있는 "전 세계 카메라" 변환이 포함 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-276">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="69dc9-277">예를 들어이 위치 (MultiplyPoint (Vector3))에 작은 holographic 아이콘을 배치 하 고 카메라가 연결 된 방향으로 약간의 화살표 (CameraToWorld (MultiplyVector))를 그릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-277">For example, you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="69dc9-278">태그/패턴/포스터/개체 추적</span><span class="sxs-lookup"><span data-stu-id="69dc9-278">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="69dc9-279">많은 혼합 현실 응용 프로그램에서는 인식할 수 있는 이미지 또는 시각적 패턴을 사용 하 여 공간에 추적 가능 점을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-279">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="69dc9-280">그런 다음이 요소를 기준으로 개체를 렌더링 하거나 알려진 위치를 만드는 데 사용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-280">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="69dc9-281">HoloLens를 사용 하는 경우에는 fiducials로 태그가 지정 된 실제 세계 개체 (예: QR 코드가 포함 된 TV 모니터)를 찾고, holograms를 fiducials에 배치 하 고, Wi-fi를 통해 HoloLens와 통신 하도록 설정 된 태블릿과 같은 비 HoloLens 장치와 시각적으로 연결 하는 기능이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-281">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="69dc9-282">시각적 패턴을 인식 한 다음이 개체를 응용 프로그램의 세계 공간에 놓으려면 다음과 같은 몇 가지 작업을 수행 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-282">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="69dc9-283">QR 코드, AR 태그, 얼굴 찾기, 원 추적기, OCR 등의 이미지 패턴 인식 도구 키트입니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-283">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="69dc9-284">런타임에 이미지 프레임을 수집 하 여 인식 계층으로 전달 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-284">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="69dc9-285">이미지 위치를 세계 위치 또는 세계 광선으로 다시 프로젝션 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-285">Unproject their image locations back into world positions, or likely world rays.</span></span> 
4. <span data-ttu-id="69dc9-286">이러한 세계 위치에 가상 모델 배치</span><span class="sxs-lookup"><span data-stu-id="69dc9-286">Position your virtual models over these world locations</span></span>

<span data-ttu-id="69dc9-287">몇 가지 중요 한 이미지 처리 링크:</span><span class="sxs-lookup"><span data-stu-id="69dc9-287">Some important image processing links:</span></span>
* [<span data-ttu-id="69dc9-288">OpenCV</span><span class="sxs-lookup"><span data-stu-id="69dc9-288">OpenCV</span></span>](https://opencv.org/)
* [<span data-ttu-id="69dc9-289">QR 태그</span><span class="sxs-lookup"><span data-stu-id="69dc9-289">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="69dc9-290">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="69dc9-290">FaceSDK</span></span>](https://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="69dc9-291">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="69dc9-291">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="69dc9-292">특히 장기 실행 이미지 인식 알고리즘을 처리할 때는 대화형 응용 프로그램 프레임 률을 유지 하는 것이 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-292">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="69dc9-293">이러한 이유로 일반적으로 다음과 같은 패턴을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-293">For this reason, we commonly use the following pattern:</span></span>
1. <span data-ttu-id="69dc9-294">주 스레드: 카메라 개체를 관리 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-294">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="69dc9-295">주 스레드: 새 프레임 (비동기)을 요청 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-295">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="69dc9-296">주 스레드: 추적 스레드에 새 프레임 전달</span><span class="sxs-lookup"><span data-stu-id="69dc9-296">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="69dc9-297">추적 스레드: 키 요소를 수집 하는 이미지를 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-297">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="69dc9-298">주 스레드: 찾은 키 지점과 일치 하도록 가상 모델을 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-298">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="69dc9-299">주 스레드: 2 단계에서 반복</span><span class="sxs-lookup"><span data-stu-id="69dc9-299">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="69dc9-300">일부 이미지 표식 시스템은 단일 픽셀 위치만 제공 합니다 .이 경우 다른 항목은이 섹션이 필요 하지 않은 전체 변환을 제공 하며,이는 가능한 위치의 광선과 동일 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-300">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="69dc9-301">단일 3d 위치로 이동 하려면 여러 광선을 활용 하 여 대략적인 교차를 기준으로 최종 결과를 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-301">To get to a single 3d location, we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="69dc9-302">이 작업을 수행하려면 다음 작업이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-302">To do this, you'll need to:</span></span>
1. <span data-ttu-id="69dc9-303">여러 카메라 이미지를 수집 하는 루프 가져오기</span><span class="sxs-lookup"><span data-stu-id="69dc9-303">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="69dc9-304">연결 된 기능 지점과 해당 세계 광선 찾기</span><span class="sxs-lookup"><span data-stu-id="69dc9-304">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="69dc9-305">여러 가지 세계 광선을 포함 하는 기능 사전이 있는 경우 다음 코드를 사용 하 여 이러한 광선의 교차를 해결할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-305">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="69dc9-306">두 개 이상의 추적 된 태그 위치가 지정 된 경우 사용자의 현재 시나리오에 맞게 모델링할 장면을 배치할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-306">Given two or more tracked tag locations, you can position a modelled scene to fit the user's current scenario.</span></span> <span data-ttu-id="69dc9-307">중력을 가정할 수 없는 경우 세 가지 태그 위치가 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-307">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="69dc9-308">대부분의 경우 흰색 구는 실시간 추적 된 태그 위치를 나타내고 파란색 구는 모델링할 태그 위치를 나타내는 간단한 색 구성표를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-308">In many cases, we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations.</span></span> <span data-ttu-id="69dc9-309">이를 통해 사용자는 맞춤 품질을 시각적으로 측정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-309">This allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="69dc9-310">모든 응용 프로그램에서 다음 설정을 가정 합니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-310">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="69dc9-311">모델링할 태그 위치 둘 이상</span><span class="sxs-lookup"><span data-stu-id="69dc9-311">Two or more modelled tag locations</span></span>
* <span data-ttu-id="69dc9-312">장면에 있는 하나의 ' 보정 공간 '은 태그의 부모입니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-312">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="69dc9-313">카메라 기능 식별자</span><span class="sxs-lookup"><span data-stu-id="69dc9-313">Camera feature identifier</span></span>
* <span data-ttu-id="69dc9-314">모델링할 태그를 실시간 태그와 맞추기 위해 보정 공간을 이동 하는 동작입니다. 모델링할 표식 자체가 아닌 부모 공간은 이동 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="69dc9-314">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="69dc9-315">Led 또는 다른 인식기 라이브러리를 사용 하 여 태그가 지정 된 고정 또는 실제 개체/얼굴 이동 추적 또는 식별</span><span class="sxs-lookup"><span data-stu-id="69dc9-315">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="69dc9-316">예:</span><span class="sxs-lookup"><span data-stu-id="69dc9-316">Examples:</span></span>
* <span data-ttu-id="69dc9-317">Led가 있는 산업 로봇 (또는 느린 개체 이동에 대 한 QR 코드)</span><span class="sxs-lookup"><span data-stu-id="69dc9-317">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="69dc9-318">대화방의 개체 식별 및 인식</span><span class="sxs-lookup"><span data-stu-id="69dc9-318">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="69dc9-319">대화방에서 사람 식별 및 인식 (예: 얼굴에 holographic 연락처 카드 넣기)</span><span class="sxs-lookup"><span data-stu-id="69dc9-319">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="69dc9-320">참고 항목</span><span class="sxs-lookup"><span data-stu-id="69dc9-320">See also</span></span>
* [<span data-ttu-id="69dc9-321">과정이 카메라 샘플</span><span class="sxs-lookup"><span data-stu-id="69dc9-321">Locatable camera sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
* [<span data-ttu-id="69dc9-322">Unity의 위치를 찾을 수 있는 카메라</span><span class="sxs-lookup"><span data-stu-id="69dc9-322">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="69dc9-323">혼합 현실 캡처</span><span class="sxs-lookup"><span data-stu-id="69dc9-323">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="69dc9-324">개발자를 위한 혼합 현실 캡처</span><span class="sxs-lookup"><span data-stu-id="69dc9-324">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="69dc9-325">미디어 캡처 소개</span><span class="sxs-lookup"><span data-stu-id="69dc9-325">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="69dc9-326">Holographic face 추적 샘플</span><span class="sxs-lookup"><span data-stu-id="69dc9-326">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
