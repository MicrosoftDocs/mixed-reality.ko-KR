---
title: 헤드 게이즈(head-gaze) 및 커밋
description: 헤드 게이즈(head-gaze) 및 커밋 입력 모델 개요
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: 혼합 현실, 응시, 응시 타기팅, 상호 작용, 디자인
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692306"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="c481d-104">헤드 게이즈(head-gaze) 및 커밋</span><span class="sxs-lookup"><span data-stu-id="c481d-104">Head-gaze and commit</span></span>
<span data-ttu-id="c481d-105">헤드 게이즈(head-gaze) 및 커밋은 머리의 방향을 앞쪽으로 두고 개체를 타기팅한 후 보조 입력(예: 손 제스처 에어 탭 또는 음성 명령 "선택")을 사용하여 작업을 실행하는 입력 모델입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="c481d-106">이 모델은 간접 조작이 가능한 "먼" 입력 모델로 간주됩니다. 즉, 팔을 뻗어서 닿을 수 없는 콘텐츠와 상호 작용하는 데 가장 적합합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="c481d-107">장치 지원</span><span class="sxs-lookup"><span data-stu-id="c481d-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="c481d-108"><strong>입력 모델</strong></span><span class="sxs-lookup"><span data-stu-id="c481d-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="c481d-109"><a href="hololens-hardware-details.md"><strong>HoloLens(1세대)</strong></a></span><span class="sxs-lookup"><span data-stu-id="c481d-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="c481d-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="c481d-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="c481d-111"><a href="immersive-headset-hardware-details.md"><strong>몰입형 헤드셋</strong></a></span><span class="sxs-lookup"><span data-stu-id="c481d-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="c481d-112">헤드 게이즈(head-gaze) 및 커밋</span><span class="sxs-lookup"><span data-stu-id="c481d-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="c481d-113">✔️ 권장</span><span class="sxs-lookup"><span data-stu-id="c481d-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="c481d-114">✔️ 권장(세 번째 선택 - <a href="interaction-fundamentals.md">다른 옵션 보기</a>)</span><span class="sxs-lookup"><span data-stu-id="c481d-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="c481d-115">➕ 대체 옵션</span><span class="sxs-lookup"><span data-stu-id="c481d-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="c481d-116">헤드 게이즈(head-gaze)</span><span class="sxs-lookup"><span data-stu-id="c481d-116">Head-gaze</span></span>
<span data-ttu-id="c481d-117">혼합 현실 헤드셋은 사용자 머리의 위치와 방향을 사용하여 머리 방향 벡터를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="c481d-118">사용자의 눈 사이에서 앞을 똑바로 가리키는 레이저라고 생각할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="c481d-119">이것은 사용자가 보고 있는 위치에 대한 대략적인 근사치입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="c481d-120">애플리케이션은 이 레이(ray)를 가상의 개체나 실제 개체와 교차시키고 그 위치에 커서를 그려서 사용자가 현재 타기팅하는 대상을 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="c481d-121">헤드 게이즈(head-gaze) 외에도, HoloLens 2와 같은 일부 혼합 현실 헤드셋에는 시선 응시(eye-gaze) 벡터를 생성하는 시선 추적 시스템이 포함되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="c481d-122">이를 통해 사용자가 보는 위치를 세밀하게 측정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="c481d-123">시선 응시(eye gaze)를 사용하여 응시와 커밋의 상호 작용을 구축할 수는 있지만, 디자인 제약 조건의 매우 다르기 때문에 [시선 추적 문서](eye-tracking.md)에서 별도로 다룰 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="c481d-124">커밋</span><span class="sxs-lookup"><span data-stu-id="c481d-124">Commit</span></span>
<span data-ttu-id="c481d-125">개체나 UI 요소를 타기팅한 후에, 사용자는 보조 입력을 사용하여 상호 작용하거나 "클릭"할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="c481d-126">이것을 모델의 커밋 단계라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="c481d-127">지원되는 커밋 메서드는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="c481d-128">에어 탭 동작</span><span class="sxs-lookup"><span data-stu-id="c481d-128">Air Tap gesture</span></span>
- <span data-ttu-id="c481d-129">음성 명령 "선택" 또는 대상 음성 명령 중 하나를 말하기</span><span class="sxs-lookup"><span data-stu-id="c481d-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="c481d-130">[HoloLens 클리커](hardware-accessories.md#hololens-clicker)에서 단일 단추 누르기</span><span class="sxs-lookup"><span data-stu-id="c481d-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="c481d-131">Xbox 게임 패드에서 'A' 단추 누르기</span><span class="sxs-lookup"><span data-stu-id="c481d-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="c481d-132">Xbox 적응형 컨트롤러에서 'A' 단추 누르기</span><span class="sxs-lookup"><span data-stu-id="c481d-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="c481d-133">헤드 게이즈(head-gaze) 및 에어 탭 동작</span><span class="sxs-lookup"><span data-stu-id="c481d-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="c481d-134">에어 탭은 손을 똑바로 세워서 탭하는 동작입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="c481d-135">에어 탭 동작을 하려면, 집게손가락을 준비 자세로 올린 후 엄지손가락을 모으고 위에 집게손가락을 올렸다가 놓으면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="c481d-136">HoloLens 1에서는 에어 탭이 가장 일반적인 보조 입력 수단입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![손가락을 준비 자세로 놓은 후, 탭하거나 클릭하는 동작](images/readyandpress.jpg)<br>

<span data-ttu-id="c481d-138">에어 탭은 HoloLens 2에서도 사용할 수 있으며 원래 버전보다 편해졌습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="c481d-139">손을 똑바로 세운 자세를 유지하기만 하면 거의 모든 유형의 손가락 모으기 동작이 지원됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="c481d-140">따라서 사용자가 동작을 배우고 수행하기 훨씬 쉽습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="c481d-141">새로운 에어 탭 동작은 동일한 API를 통해 기존 동작을 대체하기 때문에, HoloLens 2를 다시 컴파일하면 기존 애플리케이션이 새로운 동작을 자동으로 이해합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="c481d-142">헤드 게이즈(head-gaze) 및 "선택" 음성 명령</span><span class="sxs-lookup"><span data-stu-id="c481d-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="c481d-143">음성 명령은 혼합 현실의 주요 상호 작용 메서드 중 하나입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="c481d-144">시스템을 제어하는 매우 강력한 "핸즈프리" 메커니즘을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="c481d-145">음성 상호 작용 모델에는 다양한 유형이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="c481d-146">일반 명령인 "선택"으로는 "클릭" 행동을 수행하거나 보조 입력으로 커밋할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="c481d-147">개체 명령인 "닫기" 또는 "더 크게 만들기"로는 작업을 수행하고 보조 입력으로 커밋할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="c481d-148">글로벌 명령인 "시작하기"에는 대상이 필요하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="c481d-149">대화 사용자 인터페이스 또는 Cortana와 같은 엔터티에는 AI 자연어 기능이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="c481d-150">사용자 지정 명령</span><span class="sxs-lookup"><span data-stu-id="c481d-150">Custom commnads</span></span>

<span data-ttu-id="c481d-151">자세한 내용과 사용 가능한 명령의 포괄적인 목록 또는 사용 방법을 알아보려면 [음성 명령](voice-design.md) 지침을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c481d-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="c481d-152">헤드 게이즈(head-gaze) 및 HoloLens 클리커</span><span class="sxs-lookup"><span data-stu-id="c481d-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="c481d-153">HoloLens 클리커는 HoloLens용으로 특별히 제작된 최초의 주변 기기이며 HoloLens 1 Development Edition에 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="c481d-154">HoloLens 클리커를 사용하면 사용자가 최소한의 손 동작으로 클릭이 가능하고 보조 입력으로 커밋할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="c481d-155">HoloLens 클리커는 BTLE(Bluetooth 저에너지)를 사용하여 HoloLens 1 또는 2에 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="c481d-156">![HoloLens 클리커](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="c481d-157">*HoloLens 클리커*</span><span class="sxs-lookup"><span data-stu-id="c481d-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="c481d-158">디바이스 페어링에 대한 추가 정보 및 지침은 [여기](hardware-accessories.md#pairing-bluetooth-accessories)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c481d-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="c481d-159">헤드 게이즈(head-gaze) 및 Xbox 무선 컨트롤러</span><span class="sxs-lookup"><span data-stu-id="c481d-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="c481d-160">Xbox 무선 컨트롤러에서는 A 단추를 사용하여 "클릭" 행동을 보조 입력으로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="c481d-161">디바이스는 시스템을 탐색하고 제어할 수 있는 기본 동작 집합에 매핑됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="c481d-162">컨트롤러를 사용자 지정하려면 Xbox Accesories 앱을 사용하여 Xbox 무선 컨트롤러를 구성하세요.</span><span class="sxs-lookup"><span data-stu-id="c481d-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="c481d-163">![Xbox 무선 컨트롤러](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="c481d-164">*Xbox 무선 컨트롤러*</span><span class="sxs-lookup"><span data-stu-id="c481d-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="c481d-165">PC와 Xbox 컨트롤러 페어링</span><span class="sxs-lookup"><span data-stu-id="c481d-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="c481d-166">헤드 게이즈(head-gaze) 및 Xbox 적응형 컨트롤러</span><span class="sxs-lookup"><span data-stu-id="c481d-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="c481d-167">주로 이동성이 제한된 게이머의 요구를 충족하도록 설계된 Xbox 적응형 컨트롤러는 혼합 현실을 더 쉽게 이용할 수 있도록 디바이스용으로 통합된 허브입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="c481d-168">Xbox 적응형 컨트롤러에서는 A 단추를 사용하여 "클릭" 행동을 보조 입력으로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="c481d-169">디바이스는 시스템을 탐색하고 제어할 수 있는 기본 동작 집합에 매핑됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="c481d-170">컨트롤러를 사용자 지정하려면 Xbox Accesories 앱을 사용하여 Xbox 적응형 컨트롤러를 구성하세요.</span><span class="sxs-lookup"><span data-stu-id="c481d-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="c481d-171">![Xbox 적응형 컨트롤러](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="c481d-172">*Xbox 적응형 컨트롤러*</span><span class="sxs-lookup"><span data-stu-id="c481d-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="c481d-173">스위치, 단추, 마운트 및 조이스틱과 같은 외부 디바이스를 연결하여 나만의 사용자 지정 컨트롤러 환경을 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="c481d-174">단추, 엄지스틱 및 트리거 입력은 3.5mm 잭과 USB 포트를 통해 연결된 보조 장치로 제어됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="c481d-175">![Xbox 적응형 컨트롤러 포트](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="c481d-176">*Xbox 적응형 컨트롤러 포트*</span><span class="sxs-lookup"><span data-stu-id="c481d-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="c481d-177">디바이스 페어링 지침</span><span class="sxs-lookup"><span data-stu-id="c481d-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="c481d-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Xbox 사이트의 더 많은 정보</a></span><span class="sxs-lookup"><span data-stu-id="c481d-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="c481d-179">디자인 지침</span><span class="sxs-lookup"><span data-stu-id="c481d-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="c481d-180">응시 디자인에 관련된 자세한 지침은 [서비스 예정](index.md)입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="c481d-181">헤드 게이즈(head-gaze) 타기팅</span><span class="sxs-lookup"><span data-stu-id="c481d-181">Head-gaze targeting</span></span>
<span data-ttu-id="c481d-182">모든 상호 작용은 입력 형식에 관계없이 상호 작용하려는 요소를 타기팅하는 사용자의 역량에 기반합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="c481d-183">Windows Mixed Reality에서는 일반적으로 사용자의 응시를 사용하여 수행됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="c481d-184">사용자가 환경을 성공적으로 사용하도록 하려면, 시스템에서 계산된 사용자의 의도에 대한 이해와 사용자의 실제 의도가 최대한 가깝게 맞춰져야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="c481d-185">사용자가 의도한 동작을 시스템이 제대로 해석하는 정도만큼, 만족도는 높아지고 성능이 향상됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="c481d-186">대상 크기 조정 및 피드백</span><span class="sxs-lookup"><span data-stu-id="c481d-186">Target sizing and feedback</span></span>
<span data-ttu-id="c481d-187">응시 벡터는 미세 타기팅에 사용할 수 있도록 반복적으로 표시되지만 전체 타기팅(다소 큰 대상 확보)에 가장 적합한 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="c481d-188">최소 대상 크기가 1~1.5도이면 대부분의 시나리오에서 사용자의 동작이 성공해야 하지만 크기가 3도인 대상이 속도가 더 빠른 경우가 가끔 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="c481d-189">사용자가 타기팅하는 크기는 3D 요소인 경우에도 사실상 2D 영역입니다. 즉, 어떤 투영을 사용하든 타기킹이 가능한 영역이어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="c481d-190">요소가 "활성"(사용자가 요소를 타기팅하고 있음)이라는 핵심적인 단서를 제공하면 매우 유용합니다. 이러한 단서에는 눈에 보이는 "호버(hover)" 효과, 오디오 하이라이트나 클릭과 같은 처리 또는 요소와 커서의 명확한 맞춤이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="c481d-191">![2m 거리에서 최적 대상 크기](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="c481d-192">*2m 거리에서 최적 대상 크기*</span><span class="sxs-lookup"><span data-stu-id="c481d-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="c481d-193">![응시 대상 개체를 강조 표시한 예](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="c481d-194">*응시 대상 개체를 강조 표시한 예*</span><span class="sxs-lookup"><span data-stu-id="c481d-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="c481d-195">대상 배치</span><span class="sxs-lookup"><span data-stu-id="c481d-195">Target placement</span></span>
<span data-ttu-id="c481d-196">사용자는 주요 초점(보통 대략 눈 높이) 주변 영역에 대부분의 관심을 집중하기 때문에 시야에서 매우 높거나 낮게 배치된 UI 요소를 사용자가 찾지 못하는 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="c481d-197">대부분의 대상을 눈 높이 주변의 적당한 구간에 두면 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="c481d-198">사용자는 상대적으로 작은 시각 영역에 집중한다는 일반적인 경향을 감안하여(시력이 집중되는 원뿔 영역은 10도 정도임), UI 요소를 개념적으로 관련된 정도만큼 그룹화하면 사용자가 영역에서 응시 시선을 옮길 때 항목 간의 관심 연결 동작을 활용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="c481d-199">UI를 디자인할 때는 HoloLens와 몰입형 헤드셋의 시야가 크게 달라질 수 있다는 점을 감안해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="c481d-200">![Galaxy Explorer에서 응시 타기팅하기 편리하게 그룹화된 UI 요소의 예](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="c481d-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="c481d-201">*Galaxy Explorer에서 응시 타기팅하기 편리하게 그룹화된 UI 요소의 예*</span><span class="sxs-lookup"><span data-stu-id="c481d-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="c481d-202">타기팅 동작 개선</span><span class="sxs-lookup"><span data-stu-id="c481d-202">Improving targeting behaviors</span></span>
<span data-ttu-id="c481d-203">대상을 타기팅하려는 사용자의 의도를 파악(또는 근사치에 가깝게 처리)할 수 있다면 상호 작용 시 "아깝게 놓친"시도를 마치 정확하게 타기팅한 것처럼 수락하는 데 큰 도움이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="c481d-204">혼합 현실 환경에 통합할 수 있는 유용한 메서드는 매우 다양합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="c481d-205">헤드 게이즈(head-gaze) 안정화("중력 우물")</span><span class="sxs-lookup"><span data-stu-id="c481d-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="c481d-206">이 기능은 거의 항상 켜져 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="c481d-207">이 기법은 사용자에게 있을 수 있는 자연스러운 머리/목 떨림을 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="c481d-208">보기/말하기 동작 때문에 발생하는 움직임도 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="c481d-209">가장 가까운 링크 알고리즘</span><span class="sxs-lookup"><span data-stu-id="c481d-209">Closest link algorithms</span></span>
<span data-ttu-id="c481d-210">이 기법은 상호 작용이 희소한 영역에 적합합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="c481d-211">사용자가 어떤 상호 작용을 시도하는지 파악할 수 있는 가능성이 높으면, 일정 수준의 의도를 가정하여 타기팅 역량을 보완할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="c481d-212">Backdating/postdating 조치</span><span class="sxs-lookup"><span data-stu-id="c481d-212">Backdating/postdating actions</span></span>
<span data-ttu-id="c481d-213">이 메커니즘은 속도가 필요한 작업에 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="c481d-214">사용자가 일련의 타기팅/활성화 조작을 빠르게 진행하는 경우, 탭 동작 조금 전이나 후에(초기 테스트에서는 50ms 전/후가 유용함) 사용자가 초점을 맞춘 대상에 사용자의 의도를 추정하여 누락된 단계가 작동하도록 허용하는 데 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="c481d-215">다듬기</span><span class="sxs-lookup"><span data-stu-id="c481d-215">Smoothing</span></span>
<span data-ttu-id="c481d-216">이 메커니즘은 경로 이동에 유용하며, 자연스러운 머리 움직임 특성 때문에 발생하는 약간의 떨림/흔들림을 줄여줍니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="c481d-217">경로 생성 동작에 다듬기가 적용될 때, 시간보다는 크기/이동 거리에 따라 다듬기가 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="c481d-218">자성</span><span class="sxs-lookup"><span data-stu-id="c481d-218">Magnetism</span></span>
<span data-ttu-id="c481d-219">이 메커니즘은 "가장 가까운 링크" 알고리즘보다 일반적인 버전으로 생각할 수 있습니다. 사용자의 의도에 더 잘 접근하기 위해 대화형 레이아웃에 대한 지식을 사용하여 사용자가 잠재적인 대상에 접근하면 대상 쪽으로 커서를 그리거나 hitbox(표시 여부와 상관 없이)를 키웁니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="c481d-220">특히 작은 대상에 강력한 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="c481d-221">포커스 고착</span><span class="sxs-lookup"><span data-stu-id="c481d-221">Focus stickiness</span></span>
<span data-ttu-id="c481d-222">주변 상호 작용 요소 중 어디에 포커스를 둬야 할 지 결정할 때, 현재 포커스가 있는 요소에 바이어스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="c481d-223">자연 소음이 있는 두 요소 사이의 중간 지점에서 부동 상태인 경우, 불규칙한 포커스 전환 동작을 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="c481d-224">복합 제스처</span><span class="sxs-lookup"><span data-stu-id="c481d-224">Composite gestures</span></span>
<span data-ttu-id="c481d-225">앱이 개별적인 탭 동작보다 많은 것을 인식할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="c481d-226">손의 움직임으로 탭, 홀드(hold), 놓기를 결합하면 복잡한 복합 제스처를 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="c481d-227">이러한 복합 또는 높은 수준의 제스처는 개발자가 액세스할 수 있는 낮은 수준의 공간 입력 데이터(에어 탭 및 블룸)를 기반으로 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="c481d-228">에어 탭</span><span class="sxs-lookup"><span data-stu-id="c481d-228">Air tap</span></span>
<span data-ttu-id="c481d-229">에어 탭 동작은(아래의 다른 제스처와 마찬가지로) 특정한 탭에만 반응합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="c481d-230">다른 탭(예: 메뉴 또는 꽉 쥐기)을 감지하려면 위의 두 가지 주요 구성 요소 제스처 섹션에 설명된 하위 수준의 상호 작용을 앱에서 직접 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="c481d-231">길게 누르기</span><span class="sxs-lookup"><span data-stu-id="c481d-231">Tap and hold</span></span>
<span data-ttu-id="c481d-232">홀드(hold)는 에어 탭의 아래쪽 손가락 위치를 유지하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="c481d-233">에어 탭과 홀드(hold)의 조합은 개체 활성화보다는 들어 올리기와 같은 팔 동작이나, 상황에 맞는 메뉴 표시와 같은 "mousedown" 보조 상호 작용과 결합하면 다양하고 복잡한 "클릭하여 끌기" 상호 작용이 가능합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="c481d-234">단, 이러한 제스처를 디자인할 때는 주의가 필요합니다. 확장된 동작을 하는 동안 사용자가 손의 자세를 푸는 경향이 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="c481d-235">조작</span><span class="sxs-lookup"><span data-stu-id="c481d-235">Manipulation</span></span>
<span data-ttu-id="c481d-236">홀로그램이 사용자의 손 움직임에 1:1로 반응하도록 하려는 경우, 조작 제스처를 사용하여 홀로그램을 이동하거나 크기를 조정하거나 회전할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="c481d-237">이러한 1:1 움직임을 사용하는 한 가지 방식은 실제로 선을 긋거나 그릴 수 있도록 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="c481d-238">조작 제스처에 대한 초기 타기팅은 응시 또는 포인팅을 통해 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="c481d-239">길게 누르기가 시작되면 개체 조작이 손 동작에 의해 처리되고 사용자는 조작하는 동안 주위를 둘러볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="c481d-240">탐색</span><span class="sxs-lookup"><span data-stu-id="c481d-240">Navigation</span></span>
<span data-ttu-id="c481d-241">탐색 제스처는 가상 조이스틱처럼 작동하며 방사형 메뉴와 같은 UI 위젯을 탐색하는 데 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="c481d-242">길게 눌러서 제스처를 시작한 후 초기에 누른 부분을 중심으로 정규화된 3D 큐브 안에서 손을 움직입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="c481d-243">X, Y, Z 축을 따라 -1에서 1로 손을 움직일 수 있고, 시작점은 0입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="c481d-244">탐색은 속도 기반 연속 스크롤 또는 확대/축소 제스처를 빌드하는 데 사용할 수 있으며, 마우스 가운데 단추를 클릭한 다음, 마우스를 위아래로 움직여서 2D UI를 스크롤하는 것과 유사합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="c481d-245">레일을 사용한 탐색은 특정 축에서 특정 임계값에 도달할 때까지 동작을 인식하는 기능을 말합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="c481d-246">이 기능은 개발자가 애플리케이션에서 둘 이상의 축에 대한 움직임을 활성화한 경우에 유용합니다. 예를 들어, 애플리케이션이 X, Y축에서 탐색 제스처를 인식하도록 구성하고, 레일이 있는 X축도 인식하도록 구성하는 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="c481d-247">이런 경우, 손의 움직임이 Y축에서도 발생하는 경우, X축에 따라 이동하는 손의 움직임이 X축에 있는 가상의 레일 내에 유지되기만 하면 시스템에서 인식됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="c481d-248">2D 앱에서는 사용자가 세로 탐색 제스처를 사용하여 앱 내에서 스크롤, 확대/축소 또는 끌기를 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="c481d-249">그러면 앱에 가상 손가락 터치가 삽입되어 같은 유형의 터치 제스처가 시뮬레이션됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="c481d-250">단추를 선택하거나 '<스크롤/끌기/확대/축소> 도구'라고 말하면 앱의 위쪽의 표시줄에 있는 도구가 전환되기 때문에 이러한 작업 중 어떤 작업을 수행할지 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="c481d-251">복합 제스처에 대한 추가 정보</span><span class="sxs-lookup"><span data-stu-id="c481d-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="c481d-252">제스처 인식기</span><span class="sxs-lookup"><span data-stu-id="c481d-252">Gesture recognizers</span></span>

<span data-ttu-id="c481d-253">제스처 인식을 사용하여 얻을 수 있는 이점 중 하나는 현재 타기팅하고 있는 홀로그램이 받아들일 수 있는 제스처에 대해서만 제스처 인식기를 구성할 수 있다는 점입니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="c481d-254">플랫폼은 지원되는 제스처를 구별하는 데 필요한 명확성만 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="c481d-255">이런 방식으로, 에어 탭을 지원하는 홀로그램은 누르기와 놓기 사이의 시간 간격을 모두 수용할 수 있습니다. 반면에 탭과 홀드(hold)를 모두 지원하는 홀로그램은 홀드 시간 임계값이 초과되면 탭을 홀드로 승격시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="c481d-256">손 인식</span><span class="sxs-lookup"><span data-stu-id="c481d-256">Hand recognition</span></span>
<span data-ttu-id="c481d-257">HoloLens는 디바이스에 보이는 한쪽 또는 양쪽 손의 위치를 추적하여 손 제스처를 인식합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="c481d-258">HoloLens는 손이 준비 상태(집게손가락을 올리고 손등을 마주보고 있는 상태)이거나 눌린 상태(집게손가락을 내리고 손등을 마주보고 있는 상태)일 때 손을 봅니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="c481d-259">손의 자세가 다르면 HoloLens에서 무시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="c481d-260">HoloLens에서 감지되는 각각의 손에 대해 위치(방향 없음)와 눌린 상태에 액세스할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="c481d-261">손이 제스처 프레임의 가장자리에 가까워지면, 방향 벡터가 제공됩니다. 이것을 사용자에게 표시하면, HoloLens에게 보이는 위치로 손을 다시 이동하려면 손을 어떻게 움직여야 하는지를 사용자가 알 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="c481d-262">제스처 프레임</span><span class="sxs-lookup"><span data-stu-id="c481d-262">Gesture frame</span></span>
<span data-ttu-id="c481d-263">HoloLens에 제스처를 하려면 손이 "제스처 프레임" 내에 있어야 합니다. 이것은 제스처 감지 카메라가 적당히 볼 수 있는 범위를 말하며, 대략적으로 코에서 허리까지 그리고 어깨 사이를 말합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="c481d-264">사용자가 편리하게 동작을 수행하고 작업에 성공하려면 이러한 인식 영역에 대한 교육을 받아야 합니다. (그렇지 않으면 많은 사용자가 처음에는 제스처 프레임이 HoloLens를 통해 보이는 시야 내에 있을 것으로 추정하고, 상호 작용하기 위해 팔을 불편하게 위로 올리는 경우가 많습니다.)</span><span class="sxs-lookup"><span data-stu-id="c481d-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="c481d-265">HoloLens 클리커를 사용하면 제스처 프레임 안에 손이 없어도 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="c481d-266">특히 연속 제스처의 경우, 중간 제스처를 하는 동안(예: 홀로그램 개체를 옮기는 동안) 사용자가 제스처 프레임 밖으로 손을 움직여서 의도한 결과를 얻지 못할 위험이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="c481d-267">다음 세 가지 사항을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="c481d-268">제스처 프레임의 존재 및 대략적인 경계에 대한 사용자 교육(HoloLens를 설정하는 동안 학습이 제공됨)</span><span class="sxs-lookup"><span data-stu-id="c481d-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="c481d-269">시스템이 제스처를 놓쳐서 원치 않는 결과로 이어질 만큼, 제스처가 애플리케이션의 제스처 프레임 경계에 가까워지거나 벗어나는 경우 사용자에게 알려야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="c481d-270">이렇게 알려주는 시스템에 대한 주요 특징은 연구 조사에 나와 있으며, HoloLens 셸에는 이러한 유형의 알림에 유용한 사례가 제공됩니다(경계를 벗어나는 방향을 시각적으로 보여주는 중앙 커서).</span><span class="sxs-lookup"><span data-stu-id="c481d-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="c481d-271">제스처 프레임 경계를 벗어난 결과는 최소화되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="c481d-272">일반적으로, 제스처의 결과가 경계에서 멈추어야 하고 되돌릴 수는 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="c481d-273">예를 들어, 사용자가 홀로그램 개체를 방에서 건너편으로 옮기는 경우, 제스처 프레임을 벗어나면 움직임을 멈추되, 시작 지점으로 되돌리지는 말아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="c481d-274">이렇게 하면 사용자가 다소 불안해할 수도 있지만 경계를 신속하게 이해할 수 있기 때문에 의도한 전체 동작을 매번 다시 시작할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c481d-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="c481d-275">참고 항목</span><span class="sxs-lookup"><span data-stu-id="c481d-275">See also</span></span>
* [<span data-ttu-id="c481d-276">수동으로 직접 조작</span><span class="sxs-lookup"><span data-stu-id="c481d-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="c481d-277">수동으로 가리키고 커밋</span><span class="sxs-lookup"><span data-stu-id="c481d-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="c481d-278">Instinctual 상호 작용</span><span class="sxs-lookup"><span data-stu-id="c481d-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="c481d-279">헤드 게이즈 및 유지</span><span class="sxs-lookup"><span data-stu-id="c481d-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="c481d-280">음성 명령</span><span class="sxs-lookup"><span data-stu-id="c481d-280">Voice commanding</span></span>](voice-design.md)





