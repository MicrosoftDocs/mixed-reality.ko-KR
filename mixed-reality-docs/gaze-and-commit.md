---
title: 헤드 게이즈(head-gaze) 및 커밋
description: 헤드 게이즈(head-gaze) 및 커밋 입력 모델 개요
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: 혼합 현실, 응시, 응시 타기팅, 상호 작용, 디자인
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692306"
---
# <a name="head-gaze-and-commit"></a>헤드 게이즈(head-gaze) 및 커밋
헤드 게이즈(head-gaze) 및 커밋은 머리의 방향을 앞쪽으로 두고 개체를 타기팅한 후 보조 입력(예: 손 제스처 에어 탭 또는 음성 명령 "선택")을 사용하여 작업을 실행하는 입력 모델입니다. 이 모델은 간접 조작이 가능한 "먼" 입력 모델로 간주됩니다. 즉, 팔을 뻗어서 닿을 수 없는 콘텐츠와 상호 작용하는 데 가장 적합합니다.

## <a name="device-support"></a>장치 지원

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>입력 모델</strong></td>
        <td><a href="hololens-hardware-details.md"><strong>HoloLens(1세대)</strong></a></td>
        <td><strong>HoloLens 2</strong></td>
        <td><a href="immersive-headset-hardware-details.md"><strong>몰입형 헤드셋</strong></a></td>
    </tr>
     <tr>
        <td>헤드 게이즈(head-gaze) 및 커밋</td>
        <td>✔️ 권장</td>
        <td>✔️ 권장(세 번째 선택 - <a href="interaction-fundamentals.md">다른 옵션 보기</a>)</td>
        <td>➕ 대체 옵션</td>
    </tr>
</table>

## <a name="head-gaze"></a>헤드 게이즈(head-gaze)
혼합 현실 헤드셋은 사용자 머리의 위치와 방향을 사용하여 머리 방향 벡터를 결정합니다. 사용자의 눈 사이에서 앞을 똑바로 가리키는 레이저라고 생각할 수 있습니다. 이것은 사용자가 보고 있는 위치에 대한 대략적인 근사치입니다. 애플리케이션은 이 레이(ray)를 가상의 개체나 실제 개체와 교차시키고 그 위치에 커서를 그려서 사용자가 현재 타기팅하는 대상을 알려줍니다.

헤드 게이즈(head-gaze) 외에도, HoloLens 2와 같은 일부 혼합 현실 헤드셋에는 시선 응시(eye-gaze) 벡터를 생성하는 시선 추적 시스템이 포함되어 있습니다. 이를 통해 사용자가 보는 위치를 세밀하게 측정할 수 있습니다. 시선 응시(eye gaze)를 사용하여 응시와 커밋의 상호 작용을 구축할 수는 있지만, 디자인 제약 조건의 매우 다르기 때문에 [시선 추적 문서](eye-tracking.md)에서 별도로 다룰 예정입니다.

## <a name="commit"></a>커밋
개체나 UI 요소를 타기팅한 후에, 사용자는 보조 입력을 사용하여 상호 작용하거나 "클릭"할 수 있습니다. 이것을 모델의 커밋 단계라고 합니다. 지원되는 커밋 메서드는 다음과 같습니다.

- 에어 탭 동작
- 음성 명령 "선택" 또는 대상 음성 명령 중 하나를 말하기
- [HoloLens 클리커](hardware-accessories.md#hololens-clicker)에서 단일 단추 누르기
- Xbox 게임 패드에서 'A' 단추 누르기
- Xbox 적응형 컨트롤러에서 'A' 단추 누르기

### <a name="head-gaze-and-air-tap-gesture"></a>헤드 게이즈(head-gaze) 및 에어 탭 동작
에어 탭은 손을 똑바로 세워서 탭하는 동작입니다. 에어 탭 동작을 하려면, 집게손가락을 준비 자세로 올린 후 엄지손가락을 모으고 위에 집게손가락을 올렸다가 놓으면 됩니다. HoloLens 1에서는 에어 탭이 가장 일반적인 보조 입력 수단입니다.

![손가락을 준비 자세로 놓은 후, 탭하거나 클릭하는 동작](images/readyandpress.jpg)<br>

에어 탭은 HoloLens 2에서도 사용할 수 있으며 원래 버전보다 편해졌습니다. 손을 똑바로 세운 자세를 유지하기만 하면 거의 모든 유형의 손가락 모으기 동작이 지원됩니다. 따라서 사용자가 동작을 배우고 수행하기 훨씬 쉽습니다.  새로운 에어 탭 동작은 동일한 API를 통해 기존 동작을 대체하기 때문에, HoloLens 2를 다시 컴파일하면 기존 애플리케이션이 새로운 동작을 자동으로 이해합니다.

### <a name="head-gaze-and-select-voice-command"></a>헤드 게이즈(head-gaze) 및 "선택" 음성 명령
음성 명령은 혼합 현실의 주요 상호 작용 메서드 중 하나입니다. 시스템을 제어하는 매우 강력한 "핸즈프리" 메커니즘을 제공합니다. 음성 상호 작용 모델에는 다양한 유형이 있습니다.

- 일반 명령인 "선택"으로는 "클릭" 행동을 수행하거나 보조 입력으로 커밋할 수 있습니다.
- 개체 명령인 "닫기" 또는 "더 크게 만들기"로는 작업을 수행하고 보조 입력으로 커밋할 수 있습니다.
- 글로벌 명령인 "시작하기"에는 대상이 필요하지 않습니다.
- 대화 사용자 인터페이스 또는 Cortana와 같은 엔터티에는 AI 자연어 기능이 있습니다.
- 사용자 지정 명령

자세한 내용과 사용 가능한 명령의 포괄적인 목록 또는 사용 방법을 알아보려면 [음성 명령](voice-design.md) 지침을 참조하세요.


### <a name="head-gaze-and-hololens-clicker"></a>헤드 게이즈(head-gaze) 및 HoloLens 클리커
HoloLens 클리커는 HoloLens용으로 특별히 제작된 최초의 주변 기기이며 HoloLens 1 Development Edition에 포함됩니다. HoloLens 클리커를 사용하면 사용자가 최소한의 손 동작으로 클릭이 가능하고 보조 입력으로 커밋할 수 있습니다. HoloLens 클리커는 BTLE(Bluetooth 저에너지)를 사용하여 HoloLens 1 또는 2에 연결합니다.

![HoloLens 클리커](images/hololens-clicker-500px.jpg)<br>
*HoloLens 클리커*

디바이스 페어링에 대한 추가 정보 및 지침은 [여기](hardware-accessories.md#pairing-bluetooth-accessories)를 참조하세요.




### <a name="head-gaze-and-xbox-wireless-controller"></a>헤드 게이즈(head-gaze) 및 Xbox 무선 컨트롤러
Xbox 무선 컨트롤러에서는 A 단추를 사용하여 "클릭" 행동을 보조 입력으로 수행할 수 있습니다. 디바이스는 시스템을 탐색하고 제어할 수 있는 기본 동작 집합에 매핑됩니다. 컨트롤러를 사용자 지정하려면 Xbox Accesories 앱을 사용하여 Xbox 무선 컨트롤러를 구성하세요.

![Xbox 무선 컨트롤러](images/xboxcontroller.jpg)<br>
*Xbox 무선 컨트롤러*

[PC와 Xbox 컨트롤러 페어링](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a>헤드 게이즈(head-gaze) 및 Xbox 적응형 컨트롤러
주로 이동성이 제한된 게이머의 요구를 충족하도록 설계된 Xbox 적응형 컨트롤러는 혼합 현실을 더 쉽게 이용할 수 있도록 디바이스용으로 통합된 허브입니다.

Xbox 적응형 컨트롤러에서는 A 단추를 사용하여 "클릭" 행동을 보조 입력으로 수행할 수 있습니다. 디바이스는 시스템을 탐색하고 제어할 수 있는 기본 동작 집합에 매핑됩니다. 컨트롤러를 사용자 지정하려면 Xbox Accesories 앱을 사용하여 Xbox 적응형 컨트롤러를 구성하세요.

![Xbox 적응형 컨트롤러](images/xbox-adaptive-controller-devices.jpg)<br>
*Xbox 적응형 컨트롤러*

스위치, 단추, 마운트 및 조이스틱과 같은 외부 디바이스를 연결하여 나만의 사용자 지정 컨트롤러 환경을 만들 수 있습니다. 단추, 엄지스틱 및 트리거 입력은 3.5mm 잭과 USB 포트를 통해 연결된 보조 장치로 제어됩니다.

![Xbox 적응형 컨트롤러 포트](images/xbox-adaptive-controller-ports.jpg)<br>
*Xbox 적응형 컨트롤러 포트*

[디바이스 페어링 지침](hardware-accessories.md#pairing-bluetooth-accessories)

<a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Xbox 사이트의 더 많은 정보</a>


## <a name="design-guidelines"></a>디자인 지침
> [!NOTE]
> 응시 디자인에 관련된 자세한 지침은 [서비스 예정](index.md)입니다.

## <a name="head-gaze-targeting"></a>헤드 게이즈(head-gaze) 타기팅
모든 상호 작용은 입력 형식에 관계없이 상호 작용하려는 요소를 타기팅하는 사용자의 역량에 기반합니다. Windows Mixed Reality에서는 일반적으로 사용자의 응시를 사용하여 수행됩니다.
사용자가 환경을 성공적으로 사용하도록 하려면, 시스템에서 계산된 사용자의 의도에 대한 이해와 사용자의 실제 의도가 최대한 가깝게 맞춰져야 합니다. 사용자가 의도한 동작을 시스템이 제대로 해석하는 정도만큼, 만족도는 높아지고 성능이 향상됩니다.


## <a name="target-sizing-and-feedback"></a>대상 크기 조정 및 피드백
응시 벡터는 미세 타기팅에 사용할 수 있도록 반복적으로 표시되지만 전체 타기팅(다소 큰 대상 확보)에 가장 적합한 경우가 많습니다. 최소 대상 크기가 1~1.5도이면 대부분의 시나리오에서 사용자의 동작이 성공해야 하지만 크기가 3도인 대상이 속도가 더 빠른 경우가 가끔 있습니다. 사용자가 타기팅하는 크기는 3D 요소인 경우에도 사실상 2D 영역입니다. 즉, 어떤 투영을 사용하든 타기킹이 가능한 영역이어야 합니다. 요소가 "활성"(사용자가 요소를 타기팅하고 있음)이라는 핵심적인 단서를 제공하면 매우 유용합니다. 이러한 단서에는 눈에 보이는 "호버(hover)" 효과, 오디오 하이라이트나 클릭과 같은 처리 또는 요소와 커서의 명확한 맞춤이 포함됩니다.

![2m 거리에서 최적 대상 크기](images/gazetargeting-size-1000px.jpg)<br>
*2m 거리에서 최적 대상 크기*

![응시 대상 개체를 강조 표시한 예](images/gazetargeting-highlighting-640px.jpg)<br>
*응시 대상 개체를 강조 표시한 예*

## <a name="target-placement"></a>대상 배치
사용자는 주요 초점(보통 대략 눈 높이) 주변 영역에 대부분의 관심을 집중하기 때문에 시야에서 매우 높거나 낮게 배치된 UI 요소를 사용자가 찾지 못하는 경우가 많습니다. 대부분의 대상을 눈 높이 주변의 적당한 구간에 두면 도움이 됩니다. 사용자는 상대적으로 작은 시각 영역에 집중한다는 일반적인 경향을 감안하여(시력이 집중되는 원뿔 영역은 10도 정도임), UI 요소를 개념적으로 관련된 정도만큼 그룹화하면 사용자가 영역에서 응시 시선을 옮길 때 항목 간의 관심 연결 동작을 활용할 수 있습니다. UI를 디자인할 때는 HoloLens와 몰입형 헤드셋의 시야가 크게 달라질 수 있다는 점을 감안해야 합니다.

![Galaxy Explorer에서 응시 타기팅하기 편리하게 그룹화된 UI 요소의 예](images/gazetargeting-grouping-1000px.jpg)<br>
*Galaxy Explorer에서 응시 타기팅하기 편리하게 그룹화된 UI 요소의 예*

## <a name="improving-targeting-behaviors"></a>타기팅 동작 개선
대상을 타기팅하려는 사용자의 의도를 파악(또는 근사치에 가깝게 처리)할 수 있다면 상호 작용 시 "아깝게 놓친"시도를 마치 정확하게 타기팅한 것처럼 수락하는 데 큰 도움이 될 수 있습니다. 혼합 현실 환경에 통합할 수 있는 유용한 메서드는 매우 다양합니다.

### <a name="head-gaze-stabilization-gravity-wells"></a>헤드 게이즈(head-gaze) 안정화("중력 우물")
이 기능은 거의 항상 켜져 있어야 합니다. 이 기법은 사용자에게 있을 수 있는 자연스러운 머리/목 떨림을 제거합니다. 보기/말하기 동작 때문에 발생하는 움직임도 제거합니다.

### <a name="closest-link-algorithms"></a>가장 가까운 링크 알고리즘
이 기법은 상호 작용이 희소한 영역에 적합합니다. 사용자가 어떤 상호 작용을 시도하는지 파악할 수 있는 가능성이 높으면, 일정 수준의 의도를 가정하여 타기팅 역량을 보완할 수 있습니다.

### <a name="backdatingpostdating-actions"></a>Backdating/postdating 조치
이 메커니즘은 속도가 필요한 작업에 유용합니다. 사용자가 일련의 타기팅/활성화 조작을 빠르게 진행하는 경우, 탭 동작 조금 전이나 후에(초기 테스트에서는 50ms 전/후가 유용함) 사용자가 초점을 맞춘 대상에 사용자의 의도를 추정하여 누락된 단계가 작동하도록 허용하는 데 유용할 수 있습니다.

### <a name="smoothing"></a>다듬기
이 메커니즘은 경로 이동에 유용하며, 자연스러운 머리 움직임 특성 때문에 발생하는 약간의 떨림/흔들림을 줄여줍니다. 경로 생성 동작에 다듬기가 적용될 때, 시간보다는 크기/이동 거리에 따라 다듬기가 적용됩니다.

### <a name="magnetism"></a>자성
이 메커니즘은 "가장 가까운 링크" 알고리즘보다 일반적인 버전으로 생각할 수 있습니다. 사용자의 의도에 더 잘 접근하기 위해 대화형 레이아웃에 대한 지식을 사용하여 사용자가 잠재적인 대상에 접근하면 대상 쪽으로 커서를 그리거나 hitbox(표시 여부와 상관 없이)를 키웁니다. 특히 작은 대상에 강력한 수 있습니다.

### <a name="focus-stickiness"></a>포커스 고착
주변 상호 작용 요소 중 어디에 포커스를 둬야 할 지 결정할 때, 현재 포커스가 있는 요소에 바이어스를 제공합니다. 자연 소음이 있는 두 요소 사이의 중간 지점에서 부동 상태인 경우, 불규칙한 포커스 전환 동작을 줄일 수 있습니다.


## <a name="composite-gestures"></a>복합 제스처
앱이 개별적인 탭 동작보다 많은 것을 인식할 수 있습니다. 손의 움직임으로 탭, 홀드(hold), 놓기를 결합하면 복잡한 복합 제스처를 수행할 수 있습니다. 이러한 복합 또는 높은 수준의 제스처는 개발자가 액세스할 수 있는 낮은 수준의 공간 입력 데이터(에어 탭 및 블룸)를 기반으로 합니다.

### <a name="air-tap"></a>에어 탭
에어 탭 동작은(아래의 다른 제스처와 마찬가지로) 특정한 탭에만 반응합니다. 다른 탭(예: 메뉴 또는 꽉 쥐기)을 감지하려면 위의 두 가지 주요 구성 요소 제스처 섹션에 설명된 하위 수준의 상호 작용을 앱에서 직접 사용해야 합니다.

### <a name="tap-and-hold"></a>길게 누르기
홀드(hold)는 에어 탭의 아래쪽 손가락 위치를 유지하는 것입니다. 에어 탭과 홀드(hold)의 조합은 개체 활성화보다는 들어 올리기와 같은 팔 동작이나, 상황에 맞는 메뉴 표시와 같은 "mousedown" 보조 상호 작용과 결합하면 다양하고 복잡한 "클릭하여 끌기" 상호 작용이 가능합니다.
단, 이러한 제스처를 디자인할 때는 주의가 필요합니다. 확장된 동작을 하는 동안 사용자가 손의 자세를 푸는 경향이 있기 때문입니다.

### <a name="manipulation"></a>조작
홀로그램이 사용자의 손 움직임에 1:1로 반응하도록 하려는 경우, 조작 제스처를 사용하여 홀로그램을 이동하거나 크기를 조정하거나 회전할 수 있습니다. 이러한 1:1 움직임을 사용하는 한 가지 방식은 실제로 선을 긋거나 그릴 수 있도록 하는 것입니다.
조작 제스처에 대한 초기 타기팅은 응시 또는 포인팅을 통해 수행해야 합니다. 길게 누르기가 시작되면 개체 조작이 손 동작에 의해 처리되고 사용자는 조작하는 동안 주위를 둘러볼 수 있습니다.

### <a name="navigation"></a>탐색
탐색 제스처는 가상 조이스틱처럼 작동하며 방사형 메뉴와 같은 UI 위젯을 탐색하는 데 사용할 수 있습니다. 길게 눌러서 제스처를 시작한 후 초기에 누른 부분을 중심으로 정규화된 3D 큐브 안에서 손을 움직입니다. X, Y, Z 축을 따라 -1에서 1로 손을 움직일 수 있고, 시작점은 0입니다.
탐색은 속도 기반 연속 스크롤 또는 확대/축소 제스처를 빌드하는 데 사용할 수 있으며, 마우스 가운데 단추를 클릭한 다음, 마우스를 위아래로 움직여서 2D UI를 스크롤하는 것과 유사합니다.

레일을 사용한 탐색은 특정 축에서 특정 임계값에 도달할 때까지 동작을 인식하는 기능을 말합니다. 이 기능은 개발자가 애플리케이션에서 둘 이상의 축에 대한 움직임을 활성화한 경우에 유용합니다. 예를 들어, 애플리케이션이 X, Y축에서 탐색 제스처를 인식하도록 구성하고, 레일이 있는 X축도 인식하도록 구성하는 경우입니다. 이런 경우, 손의 움직임이 Y축에서도 발생하는 경우, X축에 따라 이동하는 손의 움직임이 X축에 있는 가상의 레일 내에 유지되기만 하면 시스템에서 인식됩니다.

2D 앱에서는 사용자가 세로 탐색 제스처를 사용하여 앱 내에서 스크롤, 확대/축소 또는 끌기를 수행할 수 있습니다. 그러면 앱에 가상 손가락 터치가 삽입되어 같은 유형의 터치 제스처가 시뮬레이션됩니다. 단추를 선택하거나 '<스크롤/끌기/확대/축소> 도구'라고 말하면 앱의 위쪽의 표시줄에 있는 도구가 전환되기 때문에 이러한 작업 중 어떤 작업을 수행할지 선택할 수 있습니다.

[복합 제스처에 대한 추가 정보](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a>제스처 인식기

제스처 인식을 사용하여 얻을 수 있는 이점 중 하나는 현재 타기팅하고 있는 홀로그램이 받아들일 수 있는 제스처에 대해서만 제스처 인식기를 구성할 수 있다는 점입니다. 플랫폼은 지원되는 제스처를 구별하는 데 필요한 명확성만 처리합니다. 이런 방식으로, 에어 탭을 지원하는 홀로그램은 누르기와 놓기 사이의 시간 간격을 모두 수용할 수 있습니다. 반면에 탭과 홀드(hold)를 모두 지원하는 홀로그램은 홀드 시간 임계값이 초과되면 탭을 홀드로 승격시킬 수 있습니다.

## <a name="hand-recognition"></a>손 인식
HoloLens는 디바이스에 보이는 한쪽 또는 양쪽 손의 위치를 추적하여 손 제스처를 인식합니다. HoloLens는 손이 준비 상태(집게손가락을 올리고 손등을 마주보고 있는 상태)이거나 눌린 상태(집게손가락을 내리고 손등을 마주보고 있는 상태)일 때 손을 봅니다. 손의 자세가 다르면 HoloLens에서 무시됩니다.
HoloLens에서 감지되는 각각의 손에 대해 위치(방향 없음)와 눌린 상태에 액세스할 수 있습니다. 손이 제스처 프레임의 가장자리에 가까워지면, 방향 벡터가 제공됩니다. 이것을 사용자에게 표시하면, HoloLens에게 보이는 위치로 손을 다시 이동하려면 손을 어떻게 움직여야 하는지를 사용자가 알 수 있습니다.

## <a name="gesture-frame"></a>제스처 프레임
HoloLens에 제스처를 하려면 손이 "제스처 프레임" 내에 있어야 합니다. 이것은 제스처 감지 카메라가 적당히 볼 수 있는 범위를 말하며, 대략적으로 코에서 허리까지 그리고 어깨 사이를 말합니다. 사용자가 편리하게 동작을 수행하고 작업에 성공하려면 이러한 인식 영역에 대한 교육을 받아야 합니다. (그렇지 않으면 많은 사용자가 처음에는 제스처 프레임이 HoloLens를 통해 보이는 시야 내에 있을 것으로 추정하고, 상호 작용하기 위해 팔을 불편하게 위로 올리는 경우가 많습니다.) HoloLens 클리커를 사용하면 제스처 프레임 안에 손이 없어도 됩니다.

특히 연속 제스처의 경우, 중간 제스처를 하는 동안(예: 홀로그램 개체를 옮기는 동안) 사용자가 제스처 프레임 밖으로 손을 움직여서 의도한 결과를 얻지 못할 위험이 있습니다.

다음 세 가지 사항을 고려해야 합니다.

- 제스처 프레임의 존재 및 대략적인 경계에 대한 사용자 교육(HoloLens를 설정하는 동안 학습이 제공됨)

- 시스템이 제스처를 놓쳐서 원치 않는 결과로 이어질 만큼, 제스처가 애플리케이션의 제스처 프레임 경계에 가까워지거나 벗어나는 경우 사용자에게 알려야 합니다. 이렇게 알려주는 시스템에 대한 주요 특징은 연구 조사에 나와 있으며, HoloLens 셸에는 이러한 유형의 알림에 유용한 사례가 제공됩니다(경계를 벗어나는 방향을 시각적으로 보여주는 중앙 커서).

- 제스처 프레임 경계를 벗어난 결과는 최소화되어야 합니다. 일반적으로, 제스처의 결과가 경계에서 멈추어야 하고 되돌릴 수는 없습니다. 예를 들어, 사용자가 홀로그램 개체를 방에서 건너편으로 옮기는 경우, 제스처 프레임을 벗어나면 움직임을 멈추되, 시작 지점으로 되돌리지는 말아야 합니다. 이렇게 하면 사용자가 다소 불안해할 수도 있지만 경계를 신속하게 이해할 수 있기 때문에 의도한 전체 동작을 매번 다시 시작할 필요가 없습니다.


## <a name="see-also"></a>참고 항목
* [수동으로 직접 조작](direct-manipulation.md)
* [수동으로 가리키고 커밋](point-and-commit.md)
* [Instinctual 상호 작용](interaction-fundamentals.md)
* [헤드 게이즈 및 유지](gaze-and-dwell.md)
* [음성 명령](voice-design.md)





