---
title: 눈-응시
description: HoloLens 2는 개발자에 게 사용자가 보고 있는 항목에 대 한 정보를 사용할 수 있는 기능을 제공 하 여 holographic 환경 내에서 새로운 수준의 컨텍스트 및 인간 이해를 허용 합니다.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 눈 추적, 혼합 현실, 입력, 눈에 응시, 눈동자 응시
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387598"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="689ec-104">눈동자-HoloLens에서 응시 2</span><span class="sxs-lookup"><span data-stu-id="689ec-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="689ec-105">HoloLens 2는 개발자에 게 사용자가 보고 있는 항목에 대 한 정보를 사용할 수 있는 기능을 제공 하 여 holographic 환경 내에서 새로운 수준의 컨텍스트 및 인간 이해를 허용 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="689ec-106">이 페이지는 다양 한 사용 사례에 대 한 눈 추적을 활용 하는 방법 및 눈에 잘 맞는 사용자 인터페이스를 설계할 때 검색할 내용을 개발자에 게 알려 줍니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="689ec-107">장치 지원</span><span class="sxs-lookup"><span data-stu-id="689ec-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="689ec-108"><strong>기능</strong></span><span class="sxs-lookup"><span data-stu-id="689ec-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="689ec-109"><a href="hololens-hardware-details.md"><strong>HoloLens(1세대)</strong></a></span><span class="sxs-lookup"><span data-stu-id="689ec-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="689ec-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="689ec-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="689ec-111"><a href="immersive-headset-hardware-details.md"><strong>몰입형 헤드셋</strong></a></span><span class="sxs-lookup"><span data-stu-id="689ec-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="689ec-112">눈-응시</span><span class="sxs-lookup"><span data-stu-id="689ec-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="689ec-113">❌</span><span class="sxs-lookup"><span data-stu-id="689ec-113">❌</span></span></td>
     <td><span data-ttu-id="689ec-114">✔️</span><span class="sxs-lookup"><span data-stu-id="689ec-114">✔️</span></span></td>
     <td><span data-ttu-id="689ec-115">❌</span><span class="sxs-lookup"><span data-stu-id="689ec-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="689ec-116">사용 사례</span><span class="sxs-lookup"><span data-stu-id="689ec-116">Use cases</span></span>
<span data-ttu-id="689ec-117">시선 추적을 사용하여 애플리케이션에서는 사용자가 실시간으로 보는 곳을 추적할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="689ec-118">다음 사용 사례에서는 혼합 현실에서 눈 추적에 사용할 수 있는 몇 가지 상호 작용에 대해 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="689ec-119">[혼합 현실 도구 키트](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) 는 신속 하 고 간편 하 게 눈에 띄는 대상을 선택 하는 것과 같이 눈 추적을 사용 하기 위한 몇 가지 흥미로운 방법과 강력한 예제를 제공 하는 데 유용 합니다. 사용자의 모습입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="689ec-120">사용자 의도</span><span class="sxs-lookup"><span data-stu-id="689ec-120">User intent</span></span>    
<span data-ttu-id="689ec-121">사용자에 게 표시 되는 위치와 위치에 대 한 정보는 음성, 손 및 컨트롤러와 같은 **다른 입력을 위한 강력한 컨텍스트**를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="689ec-122">이러한 컨텍스트를 다양한 작업에서 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-122">This can be used for various tasks.</span></span>
<span data-ttu-id="689ec-123">예를 들어,이는 홀로그램을 확인 하 고 "선택" ( [Head-응시 및 커밋](gaze-and-commit.md)참조) 또는 "준비 ..."를 말하는 후 사용자가 배치 하려는 위치를 확인 하 여 장면 전체에서 쉽고 빠르게 **대상** 으로 지정할 수 있습니다. 홀로그램 이며 "... ".</span><span class="sxs-lookup"><span data-stu-id="689ec-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="689ec-124">이에 대한 예는 [Mixed Reality Toolkit - 시선 지원 대상 선택](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) 및 [Mixed Reality Toolkit - 시선 지원 대상 위치 지정](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)에서 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="689ec-125">또한 사용자 의도에 대 한 예제에는 사용자가 합의서 등 가상 에이전트 및 대화형 holograms 참여를 개선 하기 위해 확인 하는 내용에 대 한 정보가 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="689ec-126">예를 들어 가상 에이전트는 현재 표시 되는 내용에 따라 사용 가능한 옵션과 해당 동작을 조정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="689ec-127">암시적 작업</span><span class="sxs-lookup"><span data-stu-id="689ec-127">Implicit actions</span></span>
<span data-ttu-id="689ec-128">암시적 작업의 범주는 사용자 의도와 밀접하게 관련되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="689ec-129">Holograms 또는 사용자 인터페이스 요소는 사용자와 시스템 간의 상호 작용을 비롯 하 여 사용자가 시스템 및 사용자가 동기화 되는 것 처럼 보일 수 있는 약간의 instinctual 방식으로 대응 한다는 것입니다. 한 가지 예는 텍스트를 계속 스크롤하거나 사용자의 응시와 동기화 할 때 사용자가 텍스트를 읽을 때 눈에 잘 맞는 **자동 스크롤** 입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="689ec-130">이에 대 한 주요 측면은 스크롤 속도가 사용자의 읽기 속도에 적응 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="689ec-131">또 다른 예로, 사용자가 포커스가 무엇 인지 정확 하 게 파악할 수 있는 눈에도 **지 원하는 확대/축소 및 이동** 이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="689ec-132">확대/축소 및 확대/축소 속도를 트리거하는 것은 음성 또는 직접 입력을 통해 제어할 수 있습니다 .이는 사용자에 게 불필요 한 제어를 제공 하는 데 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="689ec-133">이러한 디자인 지침에 대해서는 아래에서 자세히 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="689ec-134">확대 한 후 사용자는 눈에 잘 맞는 작업을 사용 하 여 자신의 환경을 탐색 하는 등의 작업을 원활 하 게 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="689ec-135">이러한 유형의 상호 작용을 나타내는 데모 예제는 [Mixed Reality Toolkit - 시선 지원 탐색](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) 샘플에서 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="689ec-136">_암시적 동작_ 에 대 한 추가 사용 사례는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="689ec-137">**스마트 알림:** 집중해서 보고 있는 위치에 알림이 계속 표시되어 짜증이 난적이 있나요?</span><span class="sxs-lookup"><span data-stu-id="689ec-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="689ec-138">사용자가 수행 하는 작업을 고려 하 여 사용자가 현재 gazing 되는 위치에서 알림을 오프셋 하 여이 환경을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="689ec-139">그러면 사용자가 읽기를 완료 한 후에는 혼란을 자동으로 해제 하 고 자동으로 해제 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="689ec-140">**주의 홀로그램:** Gazed 될 때 약간의 반응을 Holograms 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="689ec-141">이는 약간의 UI 요소부터 사용자를 다시 조회 하거나 장기간의 stare 후 사용자의 눈에 blooming을 방지 하기 시작 하기 시작 하는 가상 pet에 이르기까지 다양 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="689ec-142">이러한 상호 작용은 응용 프로그램에 대 한 흥미로운 연결 및 만족도를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="689ec-143">주의 추적</span><span class="sxs-lookup"><span data-stu-id="689ec-143">Attention tracking</span></span>   
<span data-ttu-id="689ec-144">사용자가 확인 하는 위치 또는 위치에 대 한 정보는 디자인의 유용성을 평가 하 고 효율적인 워크플로의 문제를 식별 하는 매우 강력한 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="689ec-145">눈 추적 시각화 및 분석은 다양 한 응용 프로그램 영역에서 일반적인 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="689ec-146">HoloLens 2를 사용 하면 3D holograms를 실제 컨텍스트에서 배치 하 고 그에 따라 평가할 수 있으므로 이러한 이해에 새로운 차원이 제공 됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="689ec-147">[Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) 은 눈 추적 데이터를 기록 하 고 로드 하는 기본 예제와 이러한 데이터를 시각화 하는 방법을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="689ec-148">이 영역의 다른 응용 프로그램에는 다음이 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="689ec-149">**원격 눈-응시 시각화:** 지침이 올바르게 이해 되 고 그 뒤에 있는지 확인할 수 있도록 원격 협력자가 원하는 작업을 시각화 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="689ec-150">**사용자 연구:** 주목 추적을 사용 하 여 초보자와 전문 사용자가 직접 콘텐츠를 분석 하는 방법을 탐색 하거나 의료 데이터 분석 또는 운영 체제와 같은 복잡 한 작업에 대 한 즉각적인 조정을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="689ec-151">**학습 시뮬레이션 및 성능 모니터링:** 작업 실행을 연습하면서 실행 흐름의 병목 상태를 보다 효과적으로 식별하고 작업 실행을 최적화합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="689ec-152">**평가, 광고 및 마케팅 리서치 디자인:** 눈 추적은 웹 사이트 및 제품 디자인을 evaluateing 때 시장 연구를 위한 일반적인 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="689ec-153">추가 사용 사례</span><span class="sxs-lookup"><span data-stu-id="689ec-153">Additional use cases</span></span>
- <span data-ttu-id="689ec-154">**게임:** 초능력을 갖고 싶었던 적이 있나요?</span><span class="sxs-lookup"><span data-stu-id="689ec-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="689ec-155">여기서 그 기회를 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-155">Here's your chance!</span></span> <span data-ttu-id="689ec-156">Holograms에서 바랄 levitate 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="689ec-157">눈에서 레이저 광선을 쏘세요.</span><span class="sxs-lookup"><span data-stu-id="689ec-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="689ec-158">적을 돌로 설정 하거나 고정 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="689ec-159">X-광선을 사용해서 건물을 투시하세요.</span><span class="sxs-lookup"><span data-stu-id="689ec-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="689ec-160">상상하는 만큼 이루어집니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="689ec-161">**표현적 아바타:** 눈 추적은 라이브 눈 추적 날짜를 사용 하 여 사용자가 보고 있는 항목을 나타내는 아바타의 눈에 애니메이션 효과를 주는 3D 아바타 더 많은 표현에 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="689ec-162">또한 윙크 및 깜박임을 추가하여 더 많은 표현을 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="689ec-163">**텍스트 입력:** 눈에 잘 드는 텍스트 입력에 대 한 대체 방법으로 눈 추적을 사용할 수 있습니다. 특히 음성 또는 손을 사용 하기 불편 한 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="689ec-164">시선 추적 API</span><span class="sxs-lookup"><span data-stu-id="689ec-164">Eye tracking API</span></span>
<span data-ttu-id="689ec-165">눈길을 위한 상호 작용에 대 한 특정 디자인 지침에 대해 자세히 살펴보기 전에 HoloLens 2 아이 트래커 API가 개발자에 게 제공 하는 기능을 간략하게 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="689ec-166">약 _30FPS_로 데이터를 제공 하는 단일 눈에 주목 하는--응시 원본 및 방향을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="689ec-167">예측 된 눈동자는 ca 내에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="689ec-168">1.0-1.5도를 실제 목표 중심의 시각적 각도로 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="689ec-169">약간의 부정확성이 예상되므로, 이 하한 값에 대해 약간의 여유를 계획해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="689ec-170">이 내용은 아래에서 좀 더 자세히 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-170">We will discuss this more below.</span></span> <span data-ttu-id="689ec-171">시선 추적이 정확히 작동하려면 각 사용자가 시선 추적 사용자 보정을 진행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="689ec-172">![2m 거리에서 최적 대상 크기](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="689ec-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="689ec-173">*2 미터 거리의 최적 대상 크기*</span><span class="sxs-lookup"><span data-stu-id="689ec-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="689ec-174">[아이 추적 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) 는 ' EyesPose '를 통해 액세스할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="689ec-175">눈동자-응시 디자인 지침</span><span class="sxs-lookup"><span data-stu-id="689ec-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="689ec-176">빠르게 이동하는 시선 타기팅을 활용하는 상호 작용을 구축하는 작업은 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="689ec-177">이 섹션에서는 응용 프로그램을 디자인할 때 고려해 야 할 주요 이점 및 과제를 요약 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="689ec-178">눈에 주목 하는 입력의 이점</span><span class="sxs-lookup"><span data-stu-id="689ec-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="689ec-179">**고속 가리키기.**</span><span class="sxs-lookup"><span data-stu-id="689ec-179">**High speed pointing.**</span></span> <span data-ttu-id="689ec-180">눈 근육은 우리 몸에서 가장 빠르게 반응하는 근육입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="689ec-181">**적은 노력.**</span><span class="sxs-lookup"><span data-stu-id="689ec-181">**Low effort.**</span></span> <span data-ttu-id="689ec-182">신체 움직임은 거의 필요하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="689ec-183">**암시성.**</span><span class="sxs-lookup"><span data-stu-id="689ec-183">**Implicitness.**</span></span> <span data-ttu-id="689ec-184">사용자가 "마인드 읽기"로 설명 하는 경우가 많으므로 사용자의 눈 이동에 대 한 정보는 시스템에서 사용자가 참여 하는 대상을 알 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="689ec-185">**대체 입력 채널.**</span><span class="sxs-lookup"><span data-stu-id="689ec-185">**Alternative input channel.**</span></span> <span data-ttu-id="689ec-186">눈동자-응시는 직접 조정에 따라 사용자의 경험에 대 한 직접 및 음성 입력을 위한 강력한 지원 입력을 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="689ec-187">**시각적 주의.**</span><span class="sxs-lookup"><span data-stu-id="689ec-187">**Visual attention.**</span></span> <span data-ttu-id="689ec-188">또 다른 중요 한 혜택은 사용자가 주의를 기울여야 하는 항목을 유추할 수 있다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="689ec-189">이렇게 하면 다양 한 디자인을 보다 효과적으로 평가 하 여 보다 효율적인 사용자 인터페이스 및 원격 통신에 대 한 향상 된 소셜 큐를 구체적 하는 다양 한 응용 프로그램 영역에서 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="689ec-190">간단히 말해서, 입력으로 눈에 잘 맞는를 사용 하면 빠르고 간편 하 게 컨텍스트 신호를 제공할 것입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="689ec-191">이는 사용자의 의도를 확인 하기 위해 *음성* 및 *수동* 입력과 같은 다른 입력과 함께 사용할 때 특히 강력한 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="689ec-192">눈에 직면 하는 문제-입력을 입력 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="689ec-193">많은 기능을 제공 하므로 많은 책임이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="689ec-194">눈에 superhero를 사용 하 여 만족 스러운 사용자 환경을 만들 수는 있지만,이를 위해 적절 한 고려 사항이 아닌 것이 무엇 인지 확인 하는 것도 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="689ec-195">다음은 눈에 주목 하는 입력을 사용 하 여 작업 하는 경우 고려해 야 할 몇 가지 *과제* 및 해결 방법에 대해 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="689ec-196">**눈에 주목 하는 것은 "always on"입니다** . 눈 뚜껑을 여는 순간은 환경에서 무언가를 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="689ec-197">작업을 수행 하 고 실수로 작업을 실행 하는 경우에는 시간이 너무 오래 걸리는 경우 만족 하지 않는 환경이 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="689ec-198">이 때문에 *음성 명령*, *손 모양 제스처*, *단추 클릭* 또는 확장 된 유지를 사용 하 여 눈동자를 결합 하 여 대상을 선택 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="689ec-199">또한이 솔루션을 사용 하면 사용자가 무언가를 involuntarily 하 여 너무 부담 없이 자유롭게 볼 수 있는 모드를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="689ec-200">이 이슈는 단순히 대상을 바라보면서 시각적 및 청각적 피드백을 디자인할 때도 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="689ec-201">즉각적인 팝아웃 효과 또는 호버 소리로 사용자가 당황하게 하지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="689ec-202">미묘한는 키입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-202">Subtlety is key.</span></span> <span data-ttu-id="689ec-203">디자인 권장 사항에 대해 논의하면서 아래에서 몇 가지 모범 사례를 다룰 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="689ec-204">**관찰 및 제어** 벽에 사진을 정확 하 게 똑바르게 하려고 한다고 가정 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="689ec-205">벽에 맞는지 보기 위해 테두리와 주변을 보게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="689ec-206">이제 눈을 입력으로 사용 하 여 그림을 이동 하려는 경우이 작업을 수행 하는 방법을 상상해 보세요.</span><span class="sxs-lookup"><span data-stu-id="689ec-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="689ec-207">어렵죠. 그렇지 않나요?</span><span class="sxs-lookup"><span data-stu-id="689ec-207">Difficult, isn't it?</span></span> <span data-ttu-id="689ec-208">이는 입력 및 제어에 모두 필요한 경우 눈에 주목 하는 이중 역할을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="689ec-209">**클릭하기 전에 나가기:** 빠른 대상 선택의 경우 수동 클릭 (예: 클릭 하 여 이동)을 마무리 하기 전에 사용자의 눈 응시가 이동할 수 있음을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="689ec-210">따라서 빠른 시각-응시 신호를 느린 제어 입력 (예: 음성, 실습, 컨트롤러)과 동기화 하기 위해 특별히 주의를 기울여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="689ec-211">**작은 대상:** 너무 작아서 편안 하 게 읽을 수 있는 텍스트를 읽으려고 할 때의 느낌이 있나요?</span><span class="sxs-lookup"><span data-stu-id="689ec-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="689ec-212">눈에 덕분 면 눈을 다시 조정 하 여 눈에 잘 집중할 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="689ec-213">이는 사용자가 눈동자 대상을 사용 하 여 응용 프로그램에 너무 작은 대상을 선택할 때 사용자에 게 호출할 수 있는 느낌입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="689ec-214">사용자를 위해 기분 좋고 편리한 환경을 디자인하려면 대상에 대한 시각적 각도를 2° 이상으로 유지하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="689ec-215">**비정형 눈-응시 이동** Microsoft의 눈에는 고정에서 고정으로의 신속한 이동이 수행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="689ec-216">기록된 시선 움직임의 검색 경로를 바라보면 불규칙하다는 것을 알 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="689ec-217">시선은 *머리 응시* 또는 *손 모션*과 비교할 때 빠르게 저절로 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="689ec-218">**추적 안정성:** 빛이 달라지면 눈이 새로운 상황에 적응해야 하므로 시선 추적 정확도가 약간 저하될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="689ec-219">이는 응용 프로그램 디자인에 반드시 영향을 주는 것은 아니지만, 정확성은 2 ° 제한 이내에 있으므로 사용자가 다른 보정을 실행 해야 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="689ec-220">디자인 권장 사항</span><span class="sxs-lookup"><span data-stu-id="689ec-220">Design recommendations</span></span>
<span data-ttu-id="689ec-221">다음은 눈에 잘 맞는 입력에 대해 설명 된 장점과 문제에 따라 특정 디자인 권장 사항 목록입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="689ec-222">**눈에 응시! = Head-응시:**</span><span class="sxs-lookup"><span data-stu-id="689ec-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="689ec-223">**빠르지만 불규칙한 시선 움직임이 입력 작업에 잘 맞는지 여부를 고려합니다.** 시야 (시야)에서 목표를 빠르게 선택 하는 것은 빠르게 진행 되지만 부드러운 입력 궤적 (예: drawing 또는 encircling 주석)을 필요로 하는 작업에는 적용 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="689ec-224">이 경우 손 또는 머리 가리키기가 더 나을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="689ec-225">**사용자의 눈에 잘 들지 않는 항목 (예: 슬라이더 또는 커서)을 직접 연결 하지 않습니다.**</span><span class="sxs-lookup"><span data-stu-id="689ec-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="689ec-226">커서의 경우 예상 되는 눈 모양-응시 신호의 약간의 오프셋으로 인해 "fleeing cursor" 효과가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="689ec-227">슬라이더의 경우 개체가 올바른 위치에 있는지 여부를 확인 하는 동안 눈에 따라 슬라이더를 제어 하는 double 역할과 충돌할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="689ec-228">간단히 말해서, 사용자가 신호를 정확 하 게 사용할 수 없는 경우에는 특히 사용자가 무시 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="689ec-229">**눈동자를 다른 입력과 결합 합니다.** 시각 제스처, 음성 명령 또는 단추 누름과 같은 다른 입력과의 눈 추적 통합은 몇 가지 이점을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="689ec-230">**자유로운 관찰 허용:** 주요 역할을 통해 환경을 관찰 하는 것이 중요 하다는 것을 고려 하 여 사용자는 시각적 개체, 청각 등의 의견이 나 작업을 트리거하지 않고 살펴볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="689ec-231">아이 추적을 다른 입력 컨트롤과 결합 하면 눈 추적 관찰 및 입력 제어 모드 간을 원활 하 게 전환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="689ec-232">**강력한 컨텍스트 공급자:** 음성 명령을 uttering 하거나 손 제스처를 수행 하는 동안 사용자가 확인 하는 위치와 위치에 대 한 정보를 사용 하 여 뷰 필드에서 입력을 원활 하 게 즉시 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="689ec-233">이는 아래와 같이 함수의 반환값을 데이터 프레임으로 바로 변환하는 데 사용할 수 있음을 나타냅니다. “거기에 배치”: 대상 및 목적지를 간단히 바라봄으로써 장면에서 빠르고 유연하게 홀로그램을 선택하여 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="689ec-234">**다중 모달 입력을 동기화할 필요(“클릭하기 전에 나가기” 이슈):** 긴 음성 명령 또는 핸드 제스처와 같이 보다 복잡 한 추가 입력을 통해 신속한 시각 움직임을 결합 하는 것은 추가 입력 명령을 완료 하기 전에 눈에 잘 대응할 위험이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="689ec-235">따라서 고유한 입력 컨트롤(예: 사용자 지정 손 제스처)을 만드는 경우 이러한 입력의 시작이나 대략적인 기간을 로깅하여 사용자가 이전에 응시했던 대상과 연관짓도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="689ec-236">**시선 추적 입력에 대한 미묘한 피드백:** 시스템이 의도 한 대로 작동 하는 것을 나타내기 위해 대상을 확인할 때 피드백을 제공 하는 것이 유용 하지만 미묘한 상태로 유지 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="689ec-237">여기에는 느린 혼합, 제공 및 출력, 시각적 강조 표시 또는 대상의 약간 높이기와 같이 속도가 느린 동작과 같은 기타 미묘한 대상 동작을 수행할 수 있습니다. 사용자의 현재 워크플로를 불필요 하 게 중단 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="689ec-238">**부자연스러운 시선 움직임을 입력으로 적용하지 않음:** 사용자가 응용 프로그램에서 작업을 트리거하기 위해 특정 눈 이동 (응시 제스처)을 수행 하도록 강요 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="689ec-239">**부정확성 고려:** 사용자에 게 눈에 띄는 두 가지 유형의 imprecision (offset 및 지터)를 구분 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="689ec-240">오프셋을 해결 하는 가장 쉬운 방법은 상호 작용할 수 있는 충분 한 대상을 제공 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="689ec-241">2 ° 보다 큰 시각적 각도를 참조로 사용 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="689ec-242">예를 들어, arm을 확장 하는 경우 시각적 각도의 미리 보기는 약 2 °입니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="689ec-243">이에 따라 다음과 같은 지침이 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="689ec-244">사용자가 가장 작은 대상을 선택 하도록 강요 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="689ec-245">대상이 충분히 크고 시스템이 잘 설계 된 경우, 사용자는 자신에 게 간편 하 고 마법로 상호 작용을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="689ec-246">대상이 너무 작으면 조작 경험을 피곤하고 당황스러운 것으로 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="689ec-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="689ec-247">참조</span><span class="sxs-lookup"><span data-stu-id="689ec-247">See also</span></span>
* [<span data-ttu-id="689ec-248">헤드 게이즈 및 커밋</span><span class="sxs-lookup"><span data-stu-id="689ec-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="689ec-249">헤드 및 눈-DirectX에서 응시</span><span class="sxs-lookup"><span data-stu-id="689ec-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="689ec-250">눈동자-Unity에서 응시 (혼합 현실 도구 키트)</span><span class="sxs-lookup"><span data-stu-id="689ec-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="689ec-251">손 제스처</span><span class="sxs-lookup"><span data-stu-id="689ec-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="689ec-252">음성 입력 </span><span class="sxs-lookup"><span data-stu-id="689ec-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="689ec-253">모션 컨트롤러</span><span class="sxs-lookup"><span data-stu-id="689ec-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="689ec-254">편안함</span><span class="sxs-lookup"><span data-stu-id="689ec-254">Comfort</span></span>](comfort.md)
