---
title: 시선 추적
description: 시선 추적
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 혼합 현실, 입력, 응시 눈 추적
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: 60060386305eabfac2758a2c861a43c36286b151
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/31/2019
ms.locfileid: "66453695"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="fc637-104">시선 추적 HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="fc637-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="fc637-105">HoloLens 2 컨텍스트 및 홀로그램 환경 내에서 사람이 이해의 완전히 새로운 수준에서 확인 하는 사용자는에 대 한 정보를 사용 하 여 놀라운 기능을 사용 하 여 개발자가 제공 하 여 허용 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="fc637-106">이 페이지에는 개발자가 다양 한 사용 사례에 대 한 눈 모양 추적에서 이점을 얻을 수 있습니다 하는 방법 및 눈-게이즈 기반 사용자 인터페이스를 디자인할 때 살펴봐야 할 간략히를 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="fc637-107">사용 사례</span><span class="sxs-lookup"><span data-stu-id="fc637-107">Use cases</span></span>
<span data-ttu-id="fc637-108">시선 추적 응용 프로그램을을 실시간으로 사용자가 보는 위치를 추적할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="fc637-109">이 섹션에서는 잠재적인 사용 사례 및 시선 혼합된 현실에서 추적을 사용 하 여 수행할 수 있는 새로운 상호 작용 중 일부를 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="fc637-110">시작 하기 전에 다음에서 우리 다루겠습니다 합니다 [혼합 현실 Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) 빠르고 간편 하 게 눈 지원 대상 같은 눈 추적 사용에 대 한 흥미 있고 강력한 몇 가지 예제를 제공 하므로 여러 번 선택 및 사용자가 보는 위치에 따라 텍스트를 자동으로 스크롤할 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="fc637-111">사용자 의도</span><span class="sxs-lookup"><span data-stu-id="fc637-111">User intent</span></span>    
<span data-ttu-id="fc637-112">사용자를 찾을 위치에 대 한 정보 제공을 강력한 **다른 입력에 대 한 상황에 맞는**, 음성, 실습 등 컨트롤러입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="fc637-113">이 다양 한 작업에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-113">This can be used for various tasks.</span></span>
<span data-ttu-id="fc637-114">예를 들어,이 범위에서 빠르고 손쉽게 **대상** "select" 라는를 단순히를 홀로그램에서 찾고 장면에서 (도 참조 하세요 [헤드 게이즈 및 커밋](gaze-and-commit.md)) 또는 "말해이..." 라는 가정에서 다음 "... 그리고를 홀로그램을 배치 하려는 위치를 확인 합니다. there "입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="fc637-115">이 대 한 예제를 찾을 수 있습니다 [혼합 현실 Toolkit-눈 지원 대상 선택](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) 하 고 [혼합 현실 Toolkit-대상 위치 지정 눈 지원](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="fc637-116">사용자의 의도 대 한 추가 예제에서 사용자 들에 대 한 정보를 사용 하 여 대화형 홀로그램 embodied 가상 에이전트와 engagement를 향상 시키기 위해 포함할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="fc637-117">예를 들어 가상 에이전트 사용 가능한 옵션을 조정할 수 있습니다 하 고 해당 동작을 기반으로 현재 콘텐츠를 볼 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="fc637-118">암시적 작업</span><span class="sxs-lookup"><span data-stu-id="fc637-118">Implicit actions</span></span>
<span data-ttu-id="fc637-119">암시적 작업의 범주 사용자 의도 밀접 하 게 관련이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="fc637-120">개념은 제공 또는 사용자 인터페이스 요소 느낄 수 있습니다도 않고 전혀 시스템과 상호 작용은 같은 시스템 및 사용자 동기화는 다소 instinctual 방식으로 반응 합니다. 성공적으로 구현 되어야 하므로 엄청나게 예로 예를 들어 **눈-게이즈 기반 자동 스크롤**합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="fc637-121">개념으로 간단합니다. 사용자 텍스트를 읽고에서 읽어서 유지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="fc637-122">텍스트는 점진적으로 읽는 흐름에서 사용자를 유지 하기 위해 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="fc637-123">주요 측면은 스크롤 속도가 사용자의 읽기 속도 맞게는 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="fc637-124">또 다른 예로 **눈 지원 확대/축소 및 이동** 는 사용자 수 느껴질 때가 어떤 자신이에 초점을 맞추고 방향으로 정확 하 게 분석 하는 것에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="fc637-125">트리거 확대/축소 및 확대/축소 속도 제어 음성을 통해 제어할 수 있습니다 또는 컨트롤의 느낌을 제공 하는 방법에 대 한 중요 한 입력을 전달 하 고 (다루겠습니다 아래에서 자세히 이러한 디자인 지침에 대 한) 사용자 많아지지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="fc637-126">확대/축소 되 면 사용자 원활 하 게 수행 수, 예를 들어 자신의 환경만 사용 하 여 해당 응시 소개 street 과정.</span><span class="sxs-lookup"><span data-stu-id="fc637-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="fc637-127">이러한 유형의 상호 작용에 대 한 데모 예제에서 확인할 수 있습니다 합니다 [혼합 현실 Toolkit-눈 지원 탐색](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) 샘플입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="fc637-128">추가 사용에 대 한 사례 _암시적 작업_ 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="fc637-129">**스마트 알림:** 어느 싫어합니다 집중 된 여기서 바로 팝 알림에 의해?</span><span class="sxs-lookup"><span data-stu-id="fc637-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="fc637-130">여기서 사용자는 현재에 주의를 고려를 만들 수 있습니다 더 나은!</span><span class="sxs-lookup"><span data-stu-id="fc637-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="fc637-131">여기서 사용자는 현재 하려는 다른 항목을 제한 하 고 자동으로 한 번 해제에서 오프셋 되는 알림을 모두 읽고 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="fc637-132">**세심 홀로그램:** 보려는 경우 미세 하 게 대응 하는 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="fc637-133">이 느린 blooming 꽃 것을 거슬러 올라가야 가상 애완 동물 시작 또는 장시간된 노려 후에 응시를 방지 하는 동안 약간 빛나는 UI 요소의 범위 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="fc637-134">연결 및 앱에 대 한 만족도 흥미로운 의미를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="fc637-135">추적 주의</span><span class="sxs-lookup"><span data-stu-id="fc637-135">Attention tracking</span></span>   
<span data-ttu-id="fc637-136">사용자 들이 위치에 대 한 정보는 디자인의 유용성을 평가 하 고 효율적인 작업 흐름의 문제를 식별 하는 매우 강력한 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="fc637-137">이제 시선 추적 시각화 및 분석은 일반적으로 다양 한 응용 프로그램 영역에 이미 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="fc637-138">HoloLens 2를 사용 하 여 3D 홀로그램을 실제 상황의 배치와 함께 평가 하 고 이러한 이해를 새 차원을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="fc637-139">합니다 [혼합 현실 Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) 로깅 및 시선 추적 데이터를 로드 하 고 시각화 하는 방법에 대 한 기본 예제를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="fc637-140">이 영역에서 다른 응용 프로그램 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="fc637-141">**원격 눈 게이즈 시각화 합니다.** 새로운 원격 협력자 찾으며, 예를 들어 시각화, 지침 올바르게 이해 되 고 준수 여부를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="fc637-142">**사용자 연구 연구:** 추적 주의 초급자 전문가 사용자와 콘텐츠 또는 해당 손-눈-에 대 한 조정을 복잡 한 작업 (예: 의료 데이터 또는 시스템을 운영 하는 동안 분석)를 시각적으로 분석 하는 방법은 탐색에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="fc637-143">**모의 훈련 및 성능 모니터링:** 연습 하 고 보다 효과적으로 실행 흐름의 병목 상태를 식별 하 여 작업의 실행을 최적화 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="fc637-144">**평가, 광고 및 마케팅 리서치를 디자인 합니다.** 시선 추적는 웹 사이트 및 제품 디자인 평가 시장 조사에 대 한 일반적인 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="fc637-145">추가 사용 사례</span><span class="sxs-lookup"><span data-stu-id="fc637-145">Additional use cases</span></span>
- <span data-ttu-id="fc637-146">**게임.** 하려고 한 적이 있는 만큼 강력?</span><span class="sxs-lookup"><span data-stu-id="fc637-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="fc637-147">기회는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-147">Here's your chance!</span></span> <span data-ttu-id="fc637-148">홀로그램 있습니다 응시 levitate 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="fc637-149">자신만의 레이저 빔 문제를 해결 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="fc637-150">Stone 적 변환 하거나 고정!</span><span class="sxs-lookup"><span data-stu-id="fc637-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="fc637-151">X-레이 비전을 사용 하 여 건물을 탐색 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="fc637-152">상상력을 제한 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="fc637-153">**아바타를 표현 합니다.** 눈 어떤 사용자가 현재 살펴보고 나타내려면 아바타의 눈에 애니메이션 효과를 라이브 시선 날짜를 추적을 사용 하 여 다양 한 더 표현 적인 3D 아바타를 추적 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="fc637-154">또한 윙크 및은 추가 하 여 자세한 표현성을 추가 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="fc637-155">**텍스트 입력:** 시선 추적 수 흥미로운 안으로 낮은 노력 텍스트 항목에 대 한 음성 또는 실습을 사용 하 여 편리 하 게 없는 경우에 특히 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="fc637-156">눈 추적 API</span><span class="sxs-lookup"><span data-stu-id="fc637-156">Eye tracking API</span></span>
<span data-ttu-id="fc637-157">응시로 상호 작용에 대 한 특정 디자인 지침에 대 한 정보를 살펴보기 전에 간단히 HoloLens 2 눈 추적기를 제공 하는 기능을 가리키도록 하고자 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="fc637-158">합니다 [눈 추적 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) 를 통해 액세스할 수 있습니다: `Windows.Perception.People.EyesPose`합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="fc637-159">개발자에 게 눈 게이즈 광선 (게이즈 원점과 방향을)를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="fc637-160">눈 추적기에 대 한 데이터를 제공 _30FPS_합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="fc637-161">예측된 응시 ca 내에 있다고 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="fc637-162">1.0-1.5도 실제 visual 각도에서 살펴 대상입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="fc637-163">약간의 imprecision 당연히이 하한값 값 주위에 여백을 일부 계획 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="fc637-164">이 설명 아래에 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-164">We will discuss this more below.</span></span> <span data-ttu-id="fc637-165">시선 추적 정확 하 게 작동 하려면, 각 사용자는 시선 사용자 보정 추적을 통해 이동할 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="fc637-166">![2 개의 미터 거리에 최적의 대상 크기](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="fc637-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="fc637-167">*2 개의 미터 거리에 최적의 대상 크기*</span><span class="sxs-lookup"><span data-stu-id="fc637-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="fc637-168">눈 게이즈 디자인 지침</span><span class="sxs-lookup"><span data-stu-id="fc637-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="fc637-169">대상으로 빠르게 이동 눈을 활용 하는 상호 작용을 구축 하는 것은 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="fc637-170">이 섹션에서는 주요 장점 및 앱을 디자인할 때 고려해 야 할 문제 요약 했습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="fc637-171">눈 응시 입력의 이점</span><span class="sxs-lookup"><span data-stu-id="fc637-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="fc637-172">**고속 가리키고 있습니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-172">**High speed pointing.**</span></span> <span data-ttu-id="fc637-173">모니터링 시스템은 본문의 가장 빠른 reacting 시스템이입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="fc637-174">**적은 노력 합니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-174">**Low effort.**</span></span> <span data-ttu-id="fc637-175">실제 이동 하지는 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="fc637-176">**Implicitness 합니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-176">**Implicitness.**</span></span> <span data-ttu-id="fc637-177">사용자가으로 묘사 "유의 읽기", 사용자의 눈 모양 이동에 대 한 정보 시스템을 사용자 요금제를 이용 하려는 대상 알립니다 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="fc637-178">**대체 입력된 채널입니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-178">**Alternative input channel.**</span></span> <span data-ttu-id="fc637-179">응시 직접 및 음성 입력 년간의 경험에서에서 빌드하는 직접 눈 조정에 따라 사용자에 대 한 강력한 지원 입력을 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="fc637-180">**Visual 주의가 필요 합니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-180">**Visual attention.**</span></span> <span data-ttu-id="fc637-181">또 다른 중요 한 이점은 어떤 사용자가에 주의 유추할 수 이며</span><span class="sxs-lookup"><span data-stu-id="fc637-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="fc637-182">이 더 효율적인 사용자 인터페이스에서 확인할 수 있도록 지원 하는 다양 한 설계를 효과적으로 평가 좀 더까지 다양 한 응용 프로그램 영역에 도움이 될 수 및 원격 통신에 대 한 소셜 신호를 강화 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="fc637-183">간단히 말해 입력에 잠재적으로 빠르고 간편한 상황에 맞는 신호-제공 응시를 사용 하 여이 기능은 특히 유용 다른 입력 함께에서 같은 *음성* 하 고 *수동* 입력 사용자의 의도 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="fc637-184">입력으로 gaze 눈 과제</span><span class="sxs-lookup"><span data-stu-id="fc637-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="fc637-185">전원 많은 사용 하 여 책임을 많이 제공 됩니다. 응시는 superhero 여겨질 마법 사용자 환경을 만드는 데 사용할 수 있지만, 것도 하지 않는 것이 계정에서 좋은 적절 하 게 알아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="fc637-186">다음에서 논의할 *과제* 계정과 눈 응시 입력을 사용 하 여 작업 하는 경우 해결 하는 방법을 고려 하 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="fc637-187">**에 응시가 "on"** 에 눈 뚜껑을 열고 현재 자신만 fixating 작업 환경에서 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="fc637-188">제조업체 및 잠재적으로 실수로 살펴 보셨다면 때문에 작업을 실행을 확인 응답에 모든 항목에 대 한 너무 오래 초래 끔찍한 환경을!</span><span class="sxs-lookup"><span data-stu-id="fc637-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="fc637-189">이 때문에 사용 하 여 응시를 결합 하는 것이 좋습니다는 *음성 명령*, *제스처를 전달*, *단추 클릭* 또는 트리거는 다양 한 대상에 확장된 유지 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="fc637-190">또한이 솔루션 모드는 사용자 수 자유롭게 살펴보겠습니다 involuntarily 무언가 재현해 과도 느낌 없이 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="fc637-191">이 문제 해야도 고려해 보면 단순히 대상 visual 및 청각적 피드백을 디자인할 때.</span><span class="sxs-lookup"><span data-stu-id="fc637-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="fc637-192">즉시 팝아웃 효과 사용 하 여 사용자에 과부하가 하거나 소리를 이동 하지 마십시오.</span><span class="sxs-lookup"><span data-stu-id="fc637-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="fc637-193">미묘한 키 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-193">Subtlety is key!</span></span> <span data-ttu-id="fc637-194">논의할 것 몇 가지 모범 사례 아래이 추가 대 한 디자인 권장 사항에 대해 이야기 하는 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="fc637-195">**컨트롤 및 관찰** 정확 하 게 맞출 담 벼 락에 사진을 만든다고 가정 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="fc637-196">테두리 및 주변 잘 정렬 하는 경우를 살펴봅니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="fc637-197">이제 어떻게 할 수는 동시에 그림을 이동 하 여 응시 입력으로 사용 하려는 경우를 가정해 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="fc637-198">어렵게 않습니까?</span><span class="sxs-lookup"><span data-stu-id="fc637-198">Difficult, isn't it?</span></span> <span data-ttu-id="fc637-199">모두 입력 및 제어를 위해 필요한 경우 이중 응시 역할을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="fc637-200">**클릭 하기 전의 상태로 두십시오.** 빠른 대상 선택 항목에 대 한 연구에 따르면 수동 클릭을 결정 하기 전에 사용자의 응시 이동할 수 있습니다 (예: airtap).</span><span class="sxs-lookup"><span data-stu-id="fc637-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="fc637-201">따라서 느린 컨트롤 입력 (예: 음성, 실습, 컨트롤러)를 사용 하 여 빠른 눈 게이즈 신호를 동기화 주의 기울여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="fc637-202">**작은 대상:** 텍스트를 약간 너무 작아서 편안 하 게 읽을 것 읽을 하려고 할 때 느낌이 알고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="fc637-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="fc637-203">더 나은 초점을 맞춰 자신만 다시 조정 하려고 하므로 피곤한 및 out 낡은 생각 하면 자신만의이 straining 느낌?</span><span class="sxs-lookup"><span data-stu-id="fc637-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="fc637-204">이 미치게 눈 대상을 사용 하 여 앱에서 너무 작아서 대상을 선택 하도록 요청 하는 경우 사용자에 게에서 호출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="fc637-205">디자인에 맞게 사용자에 게 재미 있고 편리한 환경을 만들 것이 좋습니다 대상 가급적 큰 visual 각도에서 적어도 2 ° 되도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="fc637-206">**눈 게이즈 이동 비정형** 눈 수행 고정 고정을 신속 하 게 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="fc637-207">기록 된 눈 모양 이동의 검색 경로 보면 비정형 확인을 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="fc637-208">자신만 이동 빠르고 비교 자동적인 변할에서 *헤드 게이즈* 또는 *동작이 전달*합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="fc637-209">**안정성을 추적 합니다.** 새 조건에 눈 조정 light 변경 시선 추적 정확도 약간 저하 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="fc637-210">이 반드시 영향을 주지 않습니다 앱 디자인을 하는 동안 정밀도와 내에 있어야 2 ° 위에 언급 한 제한 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="fc637-211">사용자는 다른 보정을 실행 해야 감소할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="fc637-212">디자인 권장 사항</span><span class="sxs-lookup"><span data-stu-id="fc637-212">Design recommendations</span></span>
<span data-ttu-id="fc637-213">다음 표에 설명 된 이점에 따라 특정 디자인 권장 사항 나열 하 고 눈에 대 한 과제 gaze 입력:</span><span class="sxs-lookup"><span data-stu-id="fc637-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="fc637-214">**응시! = 헤드 응시 합니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="fc637-215">**빠르고 비정형된 눈 모양 이동 맞는지 입력된 작업 하는 것이 좋습니다.** 빠르고 비정형 눈 모양 이동이 신속 하 게 선택할 대상 필드의 보기에서 유용한 인 것 (예: 그리기 또는 주석 encircling) 부드러운 입력된 궤적을 필요로 하는 작업에 대 한 해당 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="fc637-216">이 경우 직접 또는 head 가리키는 기본 이어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="fc637-217">**사용자의 응시 (예: 슬라이더 또는 커서)에 직접 연결 하는 것을 방지 합니다.**</span><span class="sxs-lookup"><span data-stu-id="fc637-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="fc637-218">커서의 경우이 예상된 눈 게이즈 신호에 약간의 오프셋으로 인해 "커서 달아 나" 적용에서 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="fc637-219">슬라이더의 경우 올바른 위치 인지 여부를 확인 하려는 동안 자신만 사용 하 여 슬라이더 제어의 double 역할와 충돌 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="fc637-220">간단히 말해 사용자 느낄 수 있습니다 신속 하 게 많이 사용 되 고 방해가, 특히 신호 되지 않는 경우 해당 사용자에 대해 정확 하 게 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="fc637-221">**다른 입력을 사용 하 여 응시를 결합 합니다.** 여러 가지 이점을 제공 하는 단추 누름, 손 제스처 및 음성 명령 등의 다른 입력을 사용 하 여 눈을 추적 하는 통합:</span><span class="sxs-lookup"><span data-stu-id="fc637-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="fc637-222">**관찰을 무료로 허용:** 사용자가 모든를 트리거하지 않고 살펴보겠습니다 수 있도록 반드시 눈의 주 역할은 환경을 확인할 수를 (시각, 청각 또는,...) 피드백 또는 작업입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="fc637-223">다른 입력된 컨트롤을 사용 하 여 ET 결합 ET 관찰 및 입력된 컨트롤 모드 간에 원활 하 게 전환 되 고 허용 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="fc637-224">**강력한 컨텍스트 공급자:** 여기서 사용자 음성 명령을 uttering 하는 동안 보고 또는 보기의 필드에서 입력을 손쉽게 모으면 허용 손 제스처를 수행에 대 한 정보를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="fc637-225">예를 들면 다음과 같습니다. 에 대해 "put는 있는" 신속 하 게 신속 하 게 선택 하 고 장면을 홀로그램을 보면 단순히 대상 및 대상의 위치입니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="fc637-226">**조직의 다중 모달 방식 입력 ("클릭 하기 전에 유지" 문제)를 동기화 하는 데 필요 합니다.** 더 복잡 한 추가 입력 (예: long 음성 명령 또는 손 제스처)를 사용 하 여 신속한 눈 모양 이동 결합에 응시를 사용 하 여 추가 입력된 명령을 완료 하기 전에 이동 될 위험이 갖습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="fc637-227">따라서 사용자 입력된 컨트롤 (예: 사용자 지정 손 제스처)를 만드는 경우이 입력 또는 근사치 기간 동안 새로운 사용자가 fixated에서 이전에 사용 하 여 상관 관계를 지정 하면 로그에 있는지 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="fc637-228">**시선 추적 입력에 대 한 사용자 의견 미묘한:** 대상 (시스템 의도 한 대로 작동 하는지 나타냅니다)를 살펴보고 있지만 미묘한 유지 해야 하는 경우 피드백을 제공 하는 것이 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="fc637-229">느린 입/출력 visual 강조 표시를 혼합을 포함할 수도 있고 느린 동작이 같은 기타 미묘한 대상 동작을 수행 (예를 들어 약간 늘리면 대상)는 시스템이 올바르게 검색 대상에서 사용자가 보는 나타내려면 하지만 불필요 하 게 사용자의 현재 워크플로 중단 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="fc637-230">**입력으로 이동을 자연스럽 지 눈을 적용 하지 않아도 됩니다.** 사용자가 앱에서 트리거 동작에 특정 눈 모양 이동 (게이즈 제스처)를 수행 하도록 강제 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="fc637-231">**Imprecision에 대 한 계정:** Imprecision 사용자에 게 눈에 두 가지 유형의 구분 했습니다. 오프셋 및 지터 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="fc637-232">주소 오프셋 하는 가장 쉬운 방법은 상호 작용을 충분히 큰 목표를 제공 하는 것 (참조로 visual 각도 – > 2 °: 축소판 그림은 약 2 visual 각도에서 arm (1)를 확장 하는 경우).</span><span class="sxs-lookup"><span data-stu-id="fc637-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="fc637-233">따라서 다음 지침:</span><span class="sxs-lookup"><span data-stu-id="fc637-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="fc637-234">작은 대상을 선택할 수 있는 사용자를 강제 하지 않습니다. 연구에 따르면 목표는 충분히 큰과 시스템이 잘 디자인 된 경우 사용자 설명 있으므로 간편 하 고 마법으로 상호 작용 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="fc637-235">대상 너무 작은 경우, 사용자 fatiguing와 불편 함을 느끼게 경험에 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fc637-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="fc637-236">참조</span><span class="sxs-lookup"><span data-stu-id="fc637-236">See also</span></span>
* [<span data-ttu-id="fc637-237">헤드 게이즈 및 커밋</span><span class="sxs-lookup"><span data-stu-id="fc637-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="fc637-238">DirectX의 헤드 및 눈 응시</span><span class="sxs-lookup"><span data-stu-id="fc637-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="fc637-239">Unity (혼합 현실 도구 키트)의 응시</span><span class="sxs-lookup"><span data-stu-id="fc637-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="fc637-240">손 제스처</span><span class="sxs-lookup"><span data-stu-id="fc637-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="fc637-241">음성 입력 </span><span class="sxs-lookup"><span data-stu-id="fc637-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="fc637-242">모션 컨트롤러</span><span class="sxs-lookup"><span data-stu-id="fc637-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="fc637-243">편안함</span><span class="sxs-lookup"><span data-stu-id="fc637-243">Comfort</span></span>](comfort.md)
