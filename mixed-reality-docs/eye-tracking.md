---
title: 시선 추적
description: 시선 추적
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Eye Tracking, Mixed Reality, Input, Eye Gaze
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453695"
---
# <a name="eye-tracking-on-hololens-2"></a>HoloLens 2의 시선 추적
HoloLens 2에서는 개발자에게 사용자가 바라보는 대상에 대한 정보를 사용할 수 있는 뛰어난 능력을 제공하여 홀로그래픽 환경에서 상황 및 인간을 완전히 새로운 차원으로 이해할 수 있도록 합니다. 이 페이지에서는 개발자가 다양한 사용 사례에서 시선 추적을 활용하는 방법과 시선 응시 기반 사용자 인터페이스를 디자인할 때 고려해야 할 사항을 간단히 설명합니다. 

## <a name="use-cases"></a>사용 사례
시선 추적을 사용하여 애플리케이션에서는 사용자가 실시간으로 보는 곳을 추적할 수 있습니다. 이 섹션에서는 잠재적인 사용 사례와 혼합 현실에서 시선 추적을 통해 구현할 수 있는 새로운 상호 작용에 대해 설명합니다.
시작하기 전에 집고 넘어갈 사항은 다음 내용에서 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)을 여러 번 언급한다는 것입니다. 빠르고 손쉬운 시선 지원 대상 선택, 사용자가 바라보는 위치에 따라 텍스트 자동 스크롤과 같이 시선 추적 기능이 사용되는 흥미롭고 강력한 예제를 제공하기 때문입니다. 

### <a name="user-intent"></a>사용자 의도    
사용자가 바라보는 위치에 대한 정보는 음성, 손 및 컨트롤러 등의 **다른 입력에 대한 강력한 컨텍스트**를 제공합니다.
이러한 컨텍스트를 다양한 작업에서 사용할 수 있습니다.
예를 들어, 간단히 홀로그램을 바라보고 “select”라고 말하여 빠르고 손쉽게 **타기팅**하거나([머리 응시 및 커밋](gaze-and-commit.md) 참조) "put this..."라고 말한 다음, 홀로그램을 표시할 위치를 바라보고 “there”라고 말할 수 있습니다. 이에 대한 예는 [Mixed Reality Toolkit - 시선 지원 대상 선택](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) 및 [Mixed Reality Toolkit - 시선 지원 대상 위치 지정](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)에서 찾을 수 있습니다.

사용자 의도의 추가 예로 사용자가 바라보는 대상에 대한 정보를 사용하여 포함된 가상 에이전트 및 대화형 홀로그램의 효과를 향상시키는 경우가 있습니다. 예를 들어, 가상 에이전트는 현재 본 콘텐츠를 기준으로 사용 가능한 옵션 및 해당 동작을 조정할 수 있습니다. 

### <a name="implicit-actions"></a>암시적 작업
암시적 작업의 범주는 사용자 의도와 밀접하게 관련되어 있습니다.
즉, 홀로그램이나 사용자 인터페이스 요소는 사용자가 시스템과 상호 작용한다고 느끼지 못하며, 오히려 시스템과 사용자가 동기화되어 있다고 생각할 수 있는 직관적 방식으로 반응합니다. 예를 들어, 성공적인 한 가지 예는 **시선 응시 기반 자동 스크롤**입니다. 해당 개념은 다음과 같이 간단합니다. 사용자는 텍스트를 읽으며, 계속해서 읽을 수 있습니다. 사용자가 읽기 흐름을 유지할 수 있도록 텍스트가 서서히 위로 이동합니다. 주요 측면은 스크롤 속도가 사용자의 읽기 속도에 맞게 조정된다는 것입니다.
또 다른 예로 사용자가 집중하고 있는 대상을 정확히 바라보고 있다고 느낄 수 있게 하는 **시선 지원 확대/축소 및 이동**이 있습니다. 확대/축소 트리거 및 확대/축소 속도 제어는 제어한다는 느낌을 주는 데 중요한 음성 또는 손 입력을 통해 제어할 수 있으며, 사용자가 작동의 어려움을 느끼지 않도록 합니다. 이러한 디자인 지침에 대해서는 아래에서 좀 더 자세히 설명합니다. 예를 들어, 일단 확대하고 나면, 사용자는 시선 응시만으로 거리를 원활하게 따라가면서 인접 환경을 살펴볼 수 있습니다.
이러한 유형의 상호 작용을 나타내는 데모 예제는 [Mixed Reality Toolkit - 시선 지원 탐색](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) 샘플에서 찾을 수 있습니다.

_암시적 작업_의 추가 사용 사례로는 다음이 포함될 수 있습니다.
- **스마트 알림:** 집중해서 보고 있는 위치에 알림이 계속 표시되어 짜증이 난적이 있나요? 사용자가 현재 집중하고 있는 위치를 고려해서 더 나은 환경을 구현할 수 있습니다. 사용자가 현재 보고 있는 위치에서의 알림 오프셋을 표시하여 방해 요소를 제한하고, 다 읽은 후에는 자동으로 해제되도록 합니다. 
- **주의 홀로그램:** 바라볼 때 미세하게 반응하는 홀로그램입니다. 이러한 홀로그램은 약간 빛나는 UI 요소, 느리게 피는 꽃부터 사용자가 한참 응시한 후에 사용자를 다시 바라보기 시작하거나 사용자의 시선 응시를 피하려고 하는 가상의 애완동물까지 다양할 수 있습니다. 이러한 홀로그램은 앱에 재미있는 연결성 및 만족도를 제공할 수 있습니다.

### <a name="attention-tracking"></a>주의 추적   
사용자가 바라보는 위치에 대한 정보는 디자인의 유용성을 평가하고 효율적인 작업 흐름의 문제를 식별하는 매우 강력한 도구입니다. 현재, 시선 추적 시각화 및 분석은 다양한 응용 분야에서 이미 일반적으로 사용되고 있습니다. HoloLens 2에서는 3D 홀로그램을 실제 상황에 배치하고 그에 따라 평가할 수 있으므로 이해의 폭이 훨씬 더 넓어질 수 있습니다. [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)은 시선 추적 데이터를 기록 및 로드하고 시각화하는 방법의 기본적인 예를 제공합니다.

이 영역의 다른 응용 분야로 다음이 포함될 수 있습니다. 
-   **원격 시선 응시 시각화:** 예를 들어, 원격 공동 작업자가 바라보는 대상을 시각화하여 지침이 올바르게 이해되고 준수되는지 여부를 확인합니다.
-   **사용자 연구:** 주의 추적을 사용하여 초보 사용자 및 전문가가 콘텐츠를 시각적으로 분석하는 방식이나 복잡한 작업(예: 의료 데이터 분석 또는 기계 작동)에 대한 손-시선 조정 방법을 알아볼 수 있습니다.
-   **학습 시뮬레이션 및 성능 모니터링:** 작업 실행을 연습하면서 실행 흐름의 병목 상태를 보다 효과적으로 식별하고 작업 실행을 최적화합니다.
-   **평가, 광고 및 마케팅 리서치 디자인:** 시선 추적은 마켓 리서치에서 웹 사이트 및 제품 디자인을 평가하는 데 사용하는 일반적인 도구입니다.

### <a name="additional-use-cases"></a>추가 사용 사례
- **게임:** 초능력을 갖고 싶었던 적이 있나요? 여기서 그 기회를 얻을 수 있습니다. 홀로그램을 응시하여 공중으로 올려 보내보세요. 눈에서 레이저 광선을 쏘세요. 적을 돌로 만들거나 얼려버리세요. X-광선을 사용해서 건물을 투시하세요. 상상하는 만큼 이루어집니다.  

- **표현적 아바타:** 시선 추적은 실시간 시선 추적 데이터를 사용하여 아바타의 눈이 사용자가 현재 보고 있는 대상을 나타내도록 애니메이트하여 보다 표현적인 3D 아바타를 구현할 수 있도록 지원합니다. 또한 윙크 및 깜박임을 추가하여 더 많은 표현을 추가합니다. 

- **텍스트 입력:** 특히, 음성 또는 손을 사용하기 불편한 경우에 시선 추적을 사용하여 손쉽게 텍스트를 입력할 수 있습니다. 


## <a name="eye-tracking-api"></a>시선 추적 API
시선 응시 조작을 위한 특정 디자인 지침을 자세히 알아보기 전에 HoloLens 2 아이 트래커가 제공하는 기능을 간단히 살펴보겠습니다. [시선 추적 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)는 `Windows.Perception.People.EyesPose`를 통해 액세스할 수 있습니다. 이 기능은 개발자에게 단일 시선 응시 레이(응시 원점 및 방향)를 제공합니다.
아이 트래커는 _30 FPS_에 대한 데이터를 제공합니다.
예상 시선 응시는 실제로 바라본 대상 주변에서 시각적 각도로 ca. 1.0 - 1.5도 이내에 있습니다. 약간의 부정확성이 예상되므로, 이 하한 값에 대해 약간의 여유를 계획해야 합니다. 이 내용은 아래에서 좀 더 자세히 살펴보겠습니다. 시선 추적이 정확히 작동하려면 각 사용자가 시선 추적 사용자 보정을 진행해야 합니다. 

![2m 거리에서 최적 대상 크기](images/gazetargeting-size-1000px.jpg)<br>
*2m 거리에서 최적 대상 크기*


## <a name="eye-gaze-design-guidelines"></a>시선 응시 디자인 지침
빠르게 이동하는 시선 타기팅을 활용하는 상호 작용을 구축하는 작업은 어려울 수 있습니다. 이 섹션에서는 앱을 디자인할 때 고려해야 하는 주요 장점 및 문제점을 요약해서 설명합니다. 

### <a name="benefits-of-eye-gaze-input"></a>시선 응시 입력의 이점
- **고속 가리키기.** 눈 근육은 우리 몸에서 가장 빠르게 반응하는 근육입니다. 

- **적은 노력.** 신체 움직임은 거의 필요하지 않습니다. 

- **암시성.** 종종 "독심술"이라고도 하는 사용자 시선 움직임에 대한 정보를 통해 시스템은 사용자가 교감하려는 대상을 알 수 있게 됩니다. 

- **대체 입력 채널.** 시선 응시는 손-시선을 조정하면서 사용자가 수년 동안 얻은 경험을 토대로 손 및 음성 입력을 보완하는 강력히 지원 입력을 제공할 수 있습니다.

- **시각적 주의.** 또 다른 중요한 이점은 사용자가 주의하고 있는 대상을 유추할 수 있다는 것입니다. 이러한 이점은 여러 다른 디자인을 보다 효과적으로 평가하는 것부터 원격 커뮤니케이션을 위한 보다 스마트한 사용자 인터페이스와 향상된 소셜 신호를 지원하는 것까지 다양한 분야에서 응용될 수 있습니다.

분명히 말하지만, 시선 응시를 입력으로 사용하면 빠르고 간편한 상황별 신호를 제공할 수 있습니다. 이 방식을 *음성* 및 *수동* 입력과 같은 기타 입력 방식과 함께 사용하여 사용자 의도를 확실하게 나타낼 수 있습니다.


### <a name="challenges-of-eye-gaze-as-an-input"></a>시선 응시를 입력으로 사용할 때의 해결 과제
큰 힘에는 큰 책임이 따릅니다. 시선 응시를 사용하여 슈퍼히어로와 같은 마법의 사용자 경험을 만들 수 있지만, 어떤 경우에 이러한 기능을 사용하는 것이 적절하지 않은지 파악하는 것이 중요합니다. 다음에서는 고려해야 할 몇 가지 *해결 과제*와 시선 응시 입력을 사용할 때 이러한 문제를 해결하는 방법을 살펴봅니다. 

- **시선 응시는 "항상 켜져 있음"** 눈꺼풀을 여는 순간, 눈은 환경에 있는 사물을 응시하기 시작합니다. 사물을 너무 오랫동안 바라보았기 때문에 보이는 모든 것에 반응하고 실수로 행동을 하게 된다면 끔직한 일일 것입니다.
이때문에 시선 응시를 *음성 명령*, *손 제스처*, *단추 클릭* 또는 연장된 바라보기와 결합하여 대상 선택을 트리거하는 것이 바람직한 것입니다.
또한 이 솔루션을 사용하면 사용자는 억지로 대상을 트리거한다는 느낌 없이 자유롭게 둘러볼 수 있는 모드가 구현됩니다. 이 이슈는 단순히 대상을 바라보면서 시각적 및 청각적 피드백을 디자인할 때도 고려해야 합니다.
즉각적인 팝아웃 효과 또는 호버 소리로 사용자가 당황하게 하지 않도록 합니다. 미묘함이 핵심입니다. 디자인 권장 사항에 대해 논의하면서 아래에서 몇 가지 모범 사례를 다룰 예정입니다.

- **관찰 및 제어** 사진을 벽에 정확하게 맞추려고 한다고 가정해 봅니다. 벽에 맞는지 보기 위해 테두리와 주변을 보게 됩니다. 이제 동시에 시선 응시를 입력으로 사용하여 사진을 이동하려는 경우라면 어떻게 할지 상상해보세요. 어렵죠. 그렇지 않나요? 이러한 경우는 입력 및 제어가 모두 필요할 때 시선 응시의 이중 역할을 설명하고 있습니다. 

- **클릭하기 전에 나가기:** 연구에 따르면, 빠른 대상 선택을 위해서는 수동 클릭(예: 에어 탭)을 마무리하기 전에 사용자의 시선 응시가 계속 움직일 수 있음을 보여 주었습니다. 따라서 빠른 시선 응시 신호와 더 느린 제어 입력(예: 음성, 손, 컨트롤러)을 동기화하기 위해 특히 주의해야 합니다.

- **작은 대상:** 텍스트를 읽으려고 하는 데 너무 작아서 쉽게 읽을 수 없다고 느껴지나요? 이러한 느낌이 눈을 압박하면 초점을 잘 맞추기 위해 눈을 재조정하려고 하므로 피곤하게 느껴질 수 있습니다.
강제로 사용자들이 시선 타기팅을 사용해서 앱에 있는 너무 작은 대상을 선택하도록 하면 사용자들도 이러한 느낌을 받게 됩니다.
사용자를 위해 기분 좋고 편리한 환경을 디자인하려면 대상에 대한 시각적 각도를 2° 이상으로 유지하는 것이 좋습니다.

- **불규칙한 시선 응시 움직임** 눈은 응시할 때마다 빠르게 움직입니다. 기록된 시선 움직임의 검색 경로를 바라보면 불규칙하다는 것을 알 수 있습니다. 시선은 *머리 응시* 또는 *손 모션*과 비교할 때 빠르게 저절로 이동합니다.  

- **추적 안정성:** 빛이 달라지면 눈이 새로운 상황에 적응해야 하므로 시선 추적 정확도가 약간 저하될 수 있습니다.
이러한 정확도는 위에서 언급된 2° 한도 내에서 달라지므로 앱 디자인에 반드시 영향을 미친다고 볼 수는 없습니다. 즉, 사용자가 다른 보정을 진행해야 할 수 있습니다. 


### <a name="design-recommendations"></a>디자인 권장 사항
다음에서는 시선 응시 입력의 기술된 이점과 해결 과제를 토대로 구체적인 디자인 권장 사항을 제공합니다.

1. **시선 응시 != 머리 응시:**
    - **빠르지만 불규칙한 시선 움직임이 입력 작업에 잘 맞는지 여부를 고려합니다.** 빠르고 불규칙한 시선 움직임은 시야각 너머의 대상을 빠르게 선택하는 데 유용하지만, 매끄러운 입력 궤적(예: 그림 그리기 또는 주석 둘레에 원 그리기)이 필요한 작업에는 적절하지 않습니다. 이 경우 손 또는 머리 가리키기가 더 나을 수 있습니다.
  
    - **사용자의 시선 응시에 슬라이더나 커서 등을 직접적으로 연결하지 않도록 합니다.**
커서의 경우 투영된 시선 응시 신호에서 약간의 오프셋이 발생하므로 "커서가 달아나는" 결과가 나타날 수 있습니다. 슬라이더의 경우 개체가 올바른 위치인지 여부를 확인하면서 시선으로 슬라이더를 제어하려고 하므로 충돌이 발생합니다. 간단히 말해서 사용자는 제어하기가 너무 어렵다고 느낄 수 있으며, 해당 사용자에게 신호가 정확하지 않을 경우 이러한 어려움이 두드러집니다. 
  
2. **시선 응시와 다른 입력 조합:** 손 제스처, 음성 명령 또는 단추 누르기와 같은 다른 입력과 시선 추적을 통합하면 다음과 같은 몇 가지 이점을 얻을 수 있습니다.
    - **자유로운 관찰 허용:** 시선의 주 역할이 환경을 관찰하는 것이라면, 사용자가 (시각적, 청각적 등) 피드백이나 작업을 트리거하지 않으면서 둘러볼 수 있는 것이 중요합니다. 
    ET를 다른 입력 컨트롤과 조합하면 ET 관찰과 입력 제어 모드 간을 원활하게 전환할 수 있습니다.
  
    - **강력한 컨텍스트 공급자:** 음성 명령을 발화하거나 손 제스처를 수행하면서 사용자가 바라보는 위치에 대한 정보를 사용하면 시야각을 넘어 입력을 간편하게 연결할 수 있습니다. 예를 들면 다음과 같습니다. “거기에 배치”: 대상 및 목적지를 간단히 바라봄으로써 장면에서 빠르고 유연하게 홀로그램을 선택하여 배치합니다. 

    - **다중 모달 입력을 동기화할 필요(“클릭하기 전에 나가기” 이슈):** 더 복잡한 추가 입력(예: 긴 음성 명령 또는 손 제스처)과 빠른 시선 움직임을 조합하면 추가적인 입력 명령을 끝내기 전에 시선 응시로 인해 동작이 인식될 위험이 있습니다. 따라서 고유한 입력 컨트롤(예: 사용자 지정 손 제스처)을 만드는 경우 이러한 입력의 시작이나 대략적인 기간을 로깅하여 사용자가 이전에 응시했던 대상과 연관짓도록 합니다.
    
3. **시선 추적 입력에 대한 미묘한 피드백:** 대상을 바라보는 경우 피드백을 제공(시스템 의도한 대로 작동함을 나타내기 위해)하는 것이 유용하지만 미묘한 차이를 유지해야 합니다. 여기에는 시각적 강조 표시를 느리게 블렌드 인/아웃하는 경우가 포함될 수 있고, 느린 모션(예: 대상을 서서히 늘림)과 같은 다른 미묘한 대상 동작을 수행하여 사용자의 현재 워크플로를 중단시키지 않으면서 사용자가 대상을 바라보고 있다는 사실을 시스템이 올바르게 감지하고 있음을 나타낼 수 있습니다. 

4. **부자연스러운 시선 움직임을 입력으로 적용하지 않음:** 앱에서 동작을 트리거하기 위해 강제로 사용자가 특정 눈 움직임(응시 제스처)을 수행하도록 하지 않습니다.

5. **부정확성 고려:** 사용자가 느낄 수 있는 부정확성은 오프셋 및 지터의 두 가지 유형으로 구분됩니다. 오프셋을 해결하는 가장 쉬운 방법은 상호 작용할 충분히 큰 대상을 제공하는 것입니다(시각적 각도가 2°보다 큼. 참조로, 팔을 뻗을 때 엄지손톱의 시각적 각도는 약 2°임(1)). 이에 따라 다음과 같은 지침이 적용됩니다.
    - 강제로 사용자가 작은 대상을 선택하도록 하지 않습니다. 연구에 따르면, 대상이 충분히 클 경우(또한 시스템이 잘 디자인됨) 사용자는 조작을 마법처럼 쉬운 것으로 설명합니다. 대상이 너무 작으면 조작 경험을 피곤하고 당황스러운 것으로 설명합니다.
   

## <a name="see-also"></a>참고 항목
* [헤드 게이즈 및 커밋](gaze-and-commit.md)
* [DirectX의 헤드 및 눈 응시](gaze-in-directx.md)
* [Unity의 시선 응시(Mixed Reality Toolkit)](https://aka.ms/mrtk-eyes)
* [손 제스처](gestures.md)
* [음성 입력 ](voice-design.md)
* [모션 컨트롤러](motion-controllers.md)
* [편안함](comfort.md)
