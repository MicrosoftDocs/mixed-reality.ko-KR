---
title: CVPR 2019에서 혼합 현실 헤드셋 워크숍을 위한 Computer Vision 응용 프로그램
description: 2019 6 월에 CVPR 회의에서 배달 될 혼합 현실 헤드셋 워크숍에 대 한 Computer Vision 응용 프로그램의 개요 및 일정입니다.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: 이벤트, 연구 모드, cvpr, 컴퓨터 비전, 연구, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148706"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="91a10-104">혼합 현실 헤드셋 용 Computer Vision 응용 프로그램</span><span class="sxs-lookup"><span data-stu-id="91a10-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="91a10-105">[CVPR 2019](http://cvpr2019.thecvf.com/) 와 함께 구성 됩니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="91a10-106">긴 해변 (CA)</span><span class="sxs-lookup"><span data-stu-id="91a10-106">Long Beach (CA)</span></span>

<span data-ttu-id="91a10-107">June 17, 2019 (오후)-Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="91a10-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="91a10-108">조직자</span><span class="sxs-lookup"><span data-stu-id="91a10-108">Organizers</span></span>
* <span data-ttu-id="91a10-109">Marc</span><span class="sxs-lookup"><span data-stu-id="91a10-109">Marc Pollefeys</span></span>
* <span data-ttu-id="91a10-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="91a10-110">Federica Bogo</span></span>
* <span data-ttu-id="91a10-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="91a10-111">Johannes Schönberger</span></span>
* <span data-ttu-id="91a10-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="91a10-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="91a10-113">개요</span><span class="sxs-lookup"><span data-stu-id="91a10-113">Overview</span></span>

![Teaser 이미지](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="91a10-115">Microsoft HoloLens와 같은 혼합 현실 헤드셋은 컴퓨터 비전 응용 프로그램을 개발 하기 위한 강력한 플랫폼입니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="91a10-116">HoloLens 연구 모드를 사용 하면 깊이와 IR을 비롯 한 모든 원시 이미지 센서 스트림에 대 한 액세스를 제공 하 여 장치에서 컴퓨터의 비전을 조사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="91a10-117">이제 2018 년 5 월부터 연구 모드를 사용할 수 있기 때문에 HoloLens 용으로 개발 되는 몇 가지 흥미로운 데모 및 응용 프로그램이 표시 되기 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="91a10-118">이 워크숍의 목표는 혼합 현실 응용 프로그램의 컴퓨터 비전에 관심이 있는 학생 및 연구원을 결합 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="91a10-119">워크숍은 데모와 응용 프로그램을 공유 하는 장소를 제공 하 고 응용 프로그램을 서로 혼합 하 여 응용 프로그램을 빌드하거나 이식 하는 방법에 대해 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="91a10-120">(Ego 중심) 개체 인식, 직접 및 사용자 추적, 활동 인식, 어림짐작, 3D 재구성, 장면 이해, 센서 기반 지역화, 탐색 등의 항목에 대 한 제출을 권장 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="91a10-121">용지 전송</span><span class="sxs-lookup"><span data-stu-id="91a10-121">Paper Submission</span></span>
* <span data-ttu-id="91a10-122">용지 전송 최종 기한: 5 월 17 일</span><span class="sxs-lookup"><span data-stu-id="91a10-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="91a10-123">작성자에 게 알림: 5 월 24</span><span class="sxs-lookup"><span data-stu-id="91a10-123">Notification to authors: May 24</span></span>

<span data-ttu-id="91a10-124">용지 서브 미션은 CVPR 템플릿을 사용 해야 하며 4 페이지와 참조로 제한 됩니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="91a10-125">또한 작성자가 자신의 응용 프로그램을 보여주는 비디오를 제출 하도록 권장 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="91a10-126">이전에 게시 된 작업의 서브 미션 허용 됩니다 (주 CVPR 2019 회의에 수락 된 작업 포함).</span><span class="sxs-lookup"><span data-stu-id="91a10-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="91a10-127">CMT에 제출할 수 있습니다. https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="91a10-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="91a10-128">워크숍에서 구두 프레젠테이션에 대해 용지 하위 집합이 선택 됩니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="91a10-129">그러나 데모 세션 중에는 모든 작성자가 자신의 작업을 제공 하도록 권장 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="91a10-130">일정</span><span class="sxs-lookup"><span data-stu-id="91a10-130">Schedule</span></span>
* <span data-ttu-id="91a10-131">13:30-13:45: 환영 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="91a10-132">13:45-14:15: **키 노트**: Marc 수익성 ETH 취리히/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="91a10-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="91a10-133">제목과 Egocentric는 HoloLens에서 Computer Vision 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="91a10-134">14:15-14:45: **키 노트**: 수익성 Kitani, Carnegie Mellon 대학교.</span><span class="sxs-lookup"><span data-stu-id="91a10-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="91a10-135">제목과 Egocentric 활동 및 포즈 예측.</span><span class="sxs-lookup"><span data-stu-id="91a10-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="91a10-136">14:45-15:15: **키 노트**: Dr. Yang Liu, 캘리포니아의 기술 협회.</span><span class="sxs-lookup"><span data-stu-id="91a10-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="91a10-137">제목과 확대 된 현실을 사용 하 여 시각 장애인을 위한 인지 길잡이를 켭니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="91a10-138">15:15-16:15: 휴식 및 데모.</span><span class="sxs-lookup"><span data-stu-id="91a10-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="91a10-139">16:15-16:45: **키 노트**: 수익성. Kristen Grauman, 오스틴/Facebook AI 연구에서 텍사스 대학</span><span class="sxs-lookup"><span data-stu-id="91a10-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="91a10-140">제목과 첫 번째 사람의 비디오에서 사람의 개체 상호 작용입니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="91a10-141">16:45-17:15: 구두 프레젠테이션:</span><span class="sxs-lookup"><span data-stu-id="91a10-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="91a10-142">등록은 HoloLens를 사용 하 여 쉽게 독립 실행형 orthopedic 탐색이 가능 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="91a10-143">6\.</span><span class="sxs-lookup"><span data-stu-id="91a10-143">F.</span></span> <span data-ttu-id="91a10-144">Liebmcn, Roner, von Atzigen, Wanivenhaus, Neuhaus, Spirig, Scaramuzza, Sutter, Snedeker, Farshad, Furnstahl,,.</span><span class="sxs-lookup"><span data-stu-id="91a10-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="91a10-145">HoloLens를 탐색 하 여 스테레오를 학습 합니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="91a10-146">8\.</span><span class="sxs-lookup"><span data-stu-id="91a10-146">H.</span></span> <span data-ttu-id="91a10-147">Zhan, Pekelny, Ulusoy입니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="91a10-148">17:15-17:30: 최종 설명입니다.</span><span class="sxs-lookup"><span data-stu-id="91a10-148">17:15-17:30: Final Remarks.</span></span>
